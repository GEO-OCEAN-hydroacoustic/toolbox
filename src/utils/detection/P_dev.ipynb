{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:24.965628Z",
     "start_time": "2025-03-10T18:35:24.531734Z"
    }
   },
   "source": [
    "from datetime import tzinfo\n",
    "import datetime as dt\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_name = \"../../../data/visible_events.mat\"\n",
    "data = loadmat(file_name)\n",
    "col = ['distance', 'depth', 'phase', 'travel_time', 'year', 'month', 'day', 'h', 'm', 's', 'mag', 'e1', 'e2', 'e3', 'associated_file' ]\n",
    "df = []\n",
    "for line in data['events_list'].flatten():\n",
    "    # print(line.split())\n",
    "    df.append(line.split())\n",
    "df = np.array(df)\n",
    "df = pd.DataFrame(df,columns=col)\n",
    "df.astype = {'distance'       :   'float64',\n",
    "             'depth'          :   'float64',\n",
    "             'phase'          :   'str',\n",
    "             'travel_time'    :   'float64',\n",
    "             'year'           :   'float64',\n",
    "             'month'          :   'float64',\n",
    "             'day'            :   'float64',\n",
    "             'h'              :   'float64',\n",
    "             'm'            :   'float64',\n",
    "             's'              :   'float64',\n",
    "             'mag'            :   'float64',\n",
    "             'e1'             :   'float64',\n",
    "             'e2'             :   'float64',\n",
    "             'e3'             :   'float64',\n",
    "             'associated_file':   'str' }\n",
    "df['datetime'] = pd.to_datetime(df[['year','month','day','h','m','s']],utc=True)\n",
    "df = df[['datetime','distance','depth','phase','travel_time','mag','associated_file']]\n",
    "df[\"phase\"].unique()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PKIKP', 'PKP', 'P', 'PKiKP'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:27.462315Z",
     "start_time": "2025-03-10T18:35:24.965628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "from haversine import haversine, Unit\n",
    "from obspy.taup import TauPyModel\n",
    "######################################\n",
    "PATH = 'C:/Users/Romain/PycharmProjects/NEIC_ISC_join/data'\n",
    "NAME_NEIC = '/NEIC_2018_M6.csv'\n",
    "\n",
    "######################################\n",
    "######################################\n",
    "neic = pd.read_csv(PATH + NAME_NEIC, parse_dates=['time'], date_format='ISO8601')\n",
    "\n",
    "#print(neic.columns.values)\n",
    "#['time' 'latitude' 'longitude' 'depth' 'mag' 'magType' 'nst' 'gap' 'dmin'\n",
    "# 'rms' 'net' 'id' 'updated' 'place' 'type' 'horizontalError' 'depthError'\n",
    "# 'magError' 'magNst' 'status' 'locationSource' 'magSource']\n",
    "# ELAN coords\n",
    "st_lat, st_lon = -56.4602,\t62.976\n",
    "coords = (-18.1125,-178.153)\n",
    "Elan = (st_lat, st_lon)\n",
    "dist = haversine(coords, Elan) / 111\n",
    "depth = 600\n",
    "model = TauPyModel(model=\"iasp91\")\n",
    "arrivals = model.get_travel_times(source_depth_in_km=depth,\n",
    "                              distance_in_degree=dist, phase_list=[\"P\"])\n",
    "print(dist)\n",
    "print(arrivals[0])\n",
    "\n",
    "h = datetime.datetime(2018, 8, 19, 00, 19, 40, 67)\n",
    "h = h + datetime.timedelta(seconds=arrivals[0].time)\n",
    "h"
   ],
   "id": "f3ba0544fb0643b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.83874757777151\n",
      "P phase arrival at 715.742 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 8, 19, 0, 31, 35, 742051)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:27.907286Z",
     "start_time": "2025-03-10T18:35:27.485966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.utils.data_reading.sound_data.sound_file import DatFile\n",
    "from src.utils.data_reading.sound_data.sound_file_manager import DatFilesManager"
   ],
   "id": "d20051775addf003",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:28.500674Z",
     "start_time": "2025-03-10T18:35:27.926666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import timedelta\n",
    "from utils.physics.signal.make_spectrogram import make_spectrogram\n",
    "import matplotlib.pyplot as plt\n",
    "i =14\n",
    "path = \"F:/OHASISBIO/2018/2018_ELAN_raw\"  # put a DAT directory here\n",
    "start = df['datetime'].iloc[i]+timedelta(seconds=np.float64(df['travel_time'].iloc[i]))-timedelta(minutes=5)\n",
    "start = start.replace(tzinfo=None)\n",
    "end = df['datetime'].iloc[i]+timedelta(seconds=np.float64(df['travel_time'].iloc[i]))+timedelta(minutes=5)\n",
    "end =end.replace(tzinfo=None)\n",
    "\n",
    "manager = DatFilesManager(path)\n",
    "data = manager.get_segment(start,end)\n",
    "print(manager.find_file_name(start))\n",
    "f, t, spectro = make_spectrogram(data, manager.sampling_f, t_res=0.5, f_res=0.5, return_bins=True)\n",
    "plt.figure()\n",
    "plt.imshow(spectro, aspect=\"auto\", cmap=\"jet\", extent=(t[0], t[-1], f[0], f[-1]))\n",
    "plt.axvline(x=300)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.colorbar()"
   ],
   "id": "4c7a9302c5c83382",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x220df5bacf0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:28.807065Z",
     "start_time": "2025-03-10T18:35:28.743582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "f = manager.sampling_f\n",
    "n = len(data)\n",
    "%matplotlib qt\n",
    "times = np.arange(n)/f\n",
    "print(len(times))\n",
    "print(n)\n",
    "plt.figure()\n",
    "plt.plot(times, data)\n",
    "plt.axvline(0.5*n/f, color='r')"
   ],
   "id": "d2e72f1a41050661",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143997\n",
      "143997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x220de696ff0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:29.603095Z",
     "start_time": "2025-03-10T18:35:28.995755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib\n",
    "\n",
    "# Constants\n",
    "fs = 240  # Sampling frequency (Hz)\n",
    "lowcut = 0.06 # Lower cutoff frequency for band-pass filter\n",
    "highcut = 2  # Upper cutoff frequency for band-pass filter\n",
    "\n",
    "# Load Your Data (Replace with your own data)\n",
    "# Example: Simulated seismic signal with noise\n",
    "t = times  # 60 seconds of data\n",
    "data = data\n",
    "\n",
    "# 1. Band-Pass Filter (Butterworth)\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "    # a = signal.butter(order, [low, high], btype='band',output='sos')\n",
    "    # return signal.sosfiltfilt( a, data)\n",
    "\n",
    "filtered_data = bandpass_filter(data, lowcut, highcut, fs)\n",
    "\n",
    "def wavelet_denoise(data, wavelet='db4', level=4):\n",
    "    coeffs = pywt.wavedec(data, wavelet, level=level)\n",
    "    sigma = np.median(np.abs(coeffs[-1])) / 0.6745  # Noise estimation\n",
    "    threshold = sigma * np.sqrt(2 * np.log(len(data)))\n",
    "    coeffs_denoised = [pywt.threshold(c, threshold, mode='soft') for c in coeffs]\n",
    "\n",
    "    # Reconstruct the signal\n",
    "    denoised = pywt.waverec(coeffs_denoised, wavelet)\n",
    "\n",
    "    # Ensure the output length matches the input\n",
    "    if len(denoised) > len(data):\n",
    "        denoised = denoised[:len(data)]\n",
    "    elif len(denoised) < len(data):\n",
    "        denoised = np.pad(denoised, (0, len(data) - len(denoised)), mode='edge')\n",
    "\n",
    "    return denoised\n",
    "\n",
    "denoised_data = wavelet_denoise(filtered_data)\n",
    "\n",
    "# 3. STA/LTA Detection\n",
    "def sta_lta(data, fs, sta_window=1, lta_window=10, threshold=3):\n",
    "    sta_samples = int(sta_window * fs)\n",
    "    lta_samples = int(lta_window * fs)\n",
    "\n",
    "    sta = np.convolve(data**2, np.ones(sta_samples)/sta_samples, mode='same')\n",
    "    lta = np.convolve(data**2, np.ones(lta_samples)/lta_samples, mode='same')\n",
    "\n",
    "    lta[lta == 0] = np.finfo(float).eps  # Avoid division by zero\n",
    "    ratio = sta / lta\n",
    "\n",
    "    event_indices = np.where(ratio > threshold)[0]\n",
    "    return event_indices, ratio\n",
    "\n",
    "event_indices, sta_lta_ratio = sta_lta(denoised_data, fs)\n",
    "\n",
    "# 4. Plot Results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(t, data, label=\"Raw Data\", alpha=0.6)\n",
    "plt.title(\"Raw Underwater Acoustic Signal\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(t, filtered_data, label=\"Filtered & Denoised\", color='g')\n",
    "plt.title(\"Filtered & Denoised Signal\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(t, sta_lta_ratio, label=\"STA/LTA Ratio\", color='r')\n",
    "plt.axhline(y=3, color='k', linestyle=\"--\", label=\"Threshold\")\n",
    "plt.scatter(t[event_indices], sta_lta_ratio[event_indices], color='black', marker='o', label=\"Detected P-Wave\")\n",
    "plt.title(\"STA/LTA P-Wave Detection\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "ef942981dbd1670b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: qtagg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Romain\\AppData\\Local\\Temp\\ipykernel_3136\\1867890520.py:53: RuntimeWarning: overflow encountered in square\n",
      "  sta = np.convolve(data**2, np.ones(sta_samples)/sta_samples, mode='same')\n",
      "C:\\Users\\Romain\\AppData\\Local\\Temp\\ipykernel_3136\\1867890520.py:54: RuntimeWarning: overflow encountered in square\n",
      "  lta = np.convolve(data**2, np.ones(lta_samples)/lta_samples, mode='same')\n",
      "C:\\Users\\Romain\\AppData\\Local\\Temp\\ipykernel_3136\\1867890520.py:57: RuntimeWarning: invalid value encountered in divide\n",
      "  ratio = sta / lta\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:30.534444Z",
     "start_time": "2025-03-10T18:35:29.920443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Constants\n",
    "fs = 240  # Sampling frequency (Hz)\n",
    "# Adapted filter parameters for teleseismic P-waves\n",
    "lowcut = 0.6   # Lower cutoff frequency (Hz)\n",
    "highcut = 2.0  # Upper cutoff frequency (Hz)\n",
    "t = times\n",
    "data = data\n",
    "# Assuming 'data' and 't' are already defined\n",
    "n = len(data)  # Number of samples\n",
    "p_wave_time = 0.5 * n / fs  # Expected P-wave time\n",
    "data_norm = data / np.max(np.abs(data))\n",
    "\n",
    "\n",
    "# 1. Band-Pass Filter\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    return signal.filtfilt(b, a, data), b, a\n",
    "\n",
    "filtered_data, b, a = bandpass_filter(data_norm, lowcut, highcut, fs)\n",
    "\n",
    "# 2. Wavelet Denoising\n",
    "def wavelet_denoise(data, wavelet='sym5', level=4):\n",
    "    coeffs = pywt.wavedec(data, wavelet, level=level)\n",
    "    sigma = np.median(np.abs(coeffs[-1])) / 0.6745  # Noise estimation\n",
    "    threshold = sigma * np.sqrt(2 * np.log(len(data)))\n",
    "    coeffs_denoised = [pywt.threshold(c, threshold, mode='soft') for c in coeffs]\n",
    "\n",
    "    denoised = pywt.waverec(coeffs_denoised, wavelet)\n",
    "\n",
    "    if len(denoised) > len(data):\n",
    "        denoised = denoised[:len(data)]\n",
    "    elif len(denoised) < len(data):\n",
    "        denoised = np.pad(denoised, (0, len(data) - len(denoised)), mode='edge')\n",
    "\n",
    "    return denoised\n",
    "\n",
    "denoised_data = wavelet_denoise(filtered_data)\n",
    "\n",
    "# 3. STA/LTA Detection\n",
    "def sta_lta(data, fs, sta_window=1, lta_window=10, threshold=3):\n",
    "    sta_samples = int(sta_window * fs)\n",
    "    lta_samples = int(lta_window * fs)\n",
    "\n",
    "    sta = np.convolve(data**2, np.ones(sta_samples)/sta_samples, mode='same')\n",
    "    lta = np.convolve(data**2, np.ones(lta_samples)/lta_samples, mode='same')\n",
    "\n",
    "    lta[lta == 0] = np.finfo(float).eps  # Avoid division by zero\n",
    "    ratio = sta / lta\n",
    "\n",
    "    event_indices = np.where(ratio > threshold)[0]\n",
    "    return event_indices, ratio\n",
    "\n",
    "event_indices, sta_lta_ratio = sta_lta(denoised_data, fs)\n",
    "\n",
    "# 4. Detect P-Wave in STA/LTA\n",
    "detected_p_wave_time = event_indices[0] / fs if len(event_indices) > 0 else None\n",
    "\n",
    "# 5. Plot Results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# (A) Plot Raw Data\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(t, data, label=\"Raw Data\", alpha=0.6)\n",
    "plt.axvline(p_wave_time, color='r', linestyle=\"--\", label=\"Expected P-Wave\")\n",
    "plt.title(\"Raw Underwater Acoustic Signal\")\n",
    "plt.legend()\n",
    "\n",
    "# (B) Plot Filtered Data\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(t, filtered_data, label=\"Band-Pass Filtered (0.5–15 Hz)\", color='g')\n",
    "plt.axvline(p_wave_time, color='r', linestyle=\"--\", label=\"Expected P-Wave\")\n",
    "plt.title(\"Band-Pass Filtered Signal\")\n",
    "plt.legend()\n",
    "\n",
    "# (C) Plot Denoised Data\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(t, denoised_data, label=\"Wavelet Denoised\", color='b')\n",
    "plt.axvline(p_wave_time, color='r', linestyle=\"--\", label=\"Expected P-Wave\")\n",
    "if detected_p_wave_time:\n",
    "    plt.axvline(detected_p_wave_time, color='black', linestyle=\":\", label=\"Detected P-Wave\")\n",
    "plt.title(\"Filtered & Wavelet Denoised Signal\")\n",
    "plt.legend()\n",
    "\n",
    "# (D) STA/LTA Detection\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(t, sta_lta_ratio, label=\"STA/LTA Ratio\", color='r')\n",
    "plt.axhline(y=3, color='k', linestyle=\"--\", label=\"Threshold\")\n",
    "plt.axvline(p_wave_time, color='r', linestyle=\"--\", label=\"Expected P-Wave\")\n",
    "if detected_p_wave_time:\n",
    "    plt.axvline(detected_p_wave_time, color='black', linestyle=\":\", label=\"Detected P-Wave\")\n",
    "plt.title(\"STA/LTA P-Wave Detection\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot Band-Pass Filter Response\n",
    "w, h = signal.freqz(b, a, worN=1024, fs=fs)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(w, abs(h), 'b')\n",
    "plt.title(\"Band-Pass Filter Frequency Response (0.5–15 Hz)\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Gain\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Print Detected P-Wave Time\n",
    "if detected_p_wave_time:\n",
    "    print(f\"Detected P-wave at {detected_p_wave_time:.2f} seconds (Expected ~{p_wave_time:.2f}s)\")\n",
    "else:\n",
    "    print(f\"No P-wave detected. Expected at {p_wave_time:.2f} seconds.\")\n"
   ],
   "id": "10a583432b553c0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No P-wave detected. Expected at 299.99 seconds.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:31.633400Z",
     "start_time": "2025-03-10T18:35:31.543398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%matplotlib qt\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(t,filtered_data, color='r')\n",
    "plt.plot(t, denoised_data, label=\"Wavelet Denoised\", color='b')\n",
    "plt.axvline(p_wave_time, color='r', linestyle=\"--\", label=\"Expected P-Wave\")"
   ],
   "id": "aea748672ff5aa5a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x220e7069100>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:31.895665Z",
     "start_time": "2025-03-10T18:35:31.815804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt, detrend, spectrogram\n",
    "\n",
    "# Load data\n",
    "\n",
    "fs = 240\n",
    "time = np.arange(len(data)) / fs\n",
    "\n",
    "# Detrend\n",
    "data = detrend(data, type='linear')\n",
    "\n",
    "# Design filters (MATLAB parameters)\n",
    "nyquist = fs / 2\n",
    "b_high, a_high = butter(4, 0.06 , btype='high', fs=240)  # High-pass\n",
    "b_low, a_low = butter(6, 2.1 , btype='low', fs=240)     # Low-pass\n",
    "\n",
    "# 3. Apply filters with MATLAB-like padding\n",
    "filtered_high = filtfilt(b_high, a_high, data, padtype='constant', padlen=30)\n",
    "filtered_data = filtfilt(b_low, a_low, filtered_high, padtype='constant', padlen=30)\n",
    "\n",
    "# 4. Plot results\n",
    "plt.plot(time, filtered_data, 'b', linewidth=0.75)\n",
    "plt.title(\"Python Output (MATLAB-like Padding)\")\n",
    "plt.show()"
   ],
   "id": "60f2bef4bc1be479",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:32.291174Z",
     "start_time": "2025-03-10T18:35:32.043427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import filtfilt\n",
    "\n",
    "# Sampling frequency and time vector\n",
    "Fs = 250                # 100 Hz sampling frequency\n",
    "N = n                 # Number of samples (adjust as needed)\n",
    "time =times\n",
    "\n",
    "# Simulated seismic signal:\n",
    "# For example, a low-frequency sine with some noise and a higher-frequency component.\n",
    "signal =data\n",
    "# Define filter coefficients exactly as in MATLAB for Fs = 100 Hz:\n",
    "#\n",
    "# Filter 1: Hippocampe OBS (cut ~1 Hz)\n",
    "# MATLAB: a = [1, -94/100, 0], b = [1, -1, 0]\n",
    "b1 = np.array([1, -1, 0])\n",
    "a1 = np.array([1, -94/240, 0])\n",
    "\n",
    "# Filter 2: Mermaid electronic card (cut ~0.1 Hz; weak filter)\n",
    "# MATLAB: a = [1, -9965/10000, 0], b = [1, -1, 0]\n",
    "b2 = np.array([1, -1, 0])\n",
    "a2 = np.array([1, -9965/240, 0])\n",
    "\n",
    "# Filter 3: High-pass filter cutting approximately at 0.3 Hz\n",
    "# MATLAB: a = [1, -99/100, 0], b = [1, -1, 0]\n",
    "b3 = np.array([1, -1, 0])\n",
    "a3 = np.array([1, -99/240, 0])\n",
    "\n",
    "# Apply zero-phase filtering (filtfilt applies forward and backward filtering)\n",
    "filtered_signal1 = filtfilt(b1, a1, signal)\n",
    "filtered_signal2 = filtfilt(b2, a2, signal)\n",
    "filtered_signal3 = filtfilt(b3, a3, signal)\n",
    "\n",
    "# Plotting the original and filtered signals\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(time, signal, label='Original Signal', color='gray', alpha=0.5)\n",
    "plt.plot(time, filtered_signal1, label='Hippocampe OBS (cut ~1 Hz)', linewidth=2)\n",
    "plt.plot(time, filtered_signal2, label='Mermaid Electronic Card (cut ~0.1 Hz)', linewidth=2, linestyle='--')\n",
    "plt.plot(time, filtered_signal3, label='HP Filter (cut ~0.3 Hz)', linewidth=2, linestyle='-.')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Seismic Signal Filtering with MATLAB-like Coefficients')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "fed3f5aef34903ac",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:33.778288Z",
     "start_time": "2025-03-10T18:35:33.309603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "\n",
    "# Function to downsample audio data\n",
    "def downsample_audio(data, original_fs, target_fs):\n",
    "    \"\"\"Downsample audio data to the target frequency\"\"\"\n",
    "    print(f\"Downsampling from {original_fs}Hz to {target_fs}Hz\")\n",
    "    # Calculate downsampling factor\n",
    "    factor = int(original_fs / target_fs)\n",
    "    # Apply anti-aliasing filter before downsampling\n",
    "    b, a = signal.butter(5, target_fs/2, fs=original_fs, btype='low')\n",
    "    filtered_data = signal.filtfilt(b, a, data)\n",
    "    # Downsample by taking every 'factor' sample\n",
    "    downsampled_data = filtered_data[::factor]\n",
    "    return downsampled_data, target_fs\n",
    "\n",
    "# Function to apply dehazing (using spectral subtraction)\n",
    "def dehaze_audio(data, fs, frame_size=1024, overlap=0.8):\n",
    "    \"\"\"Apply spectral subtraction for dehazing\"\"\"\n",
    "    print(\"Applying dehazing using spectral subtraction\")\n",
    "    hop_size = int(frame_size * (1 - overlap))\n",
    "    # Estimate noise profile from first few frames\n",
    "    num_noise_frames = 5\n",
    "    noise_estimate = np.zeros(frame_size // 2 + 1)\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, len(data) - frame_size, hop_size):\n",
    "        frame = data[i:i+frame_size]\n",
    "        if len(frame) < frame_size:\n",
    "            frame = np.pad(frame, (0, frame_size - len(frame)))\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Estimate noise from first few frames\n",
    "    for i in range(min(num_noise_frames, len(frames))):\n",
    "        noise_frame = frames[i]\n",
    "        noise_spectrum = np.abs(np.fft.rfft(noise_frame * np.hanning(frame_size)))\n",
    "        noise_estimate += noise_spectrum / num_noise_frames\n",
    "\n",
    "    # Apply spectral subtraction\n",
    "    result = np.zeros(len(data))\n",
    "    window = np.hanning(frame_size)\n",
    "\n",
    "    for i, frame in enumerate(frames):\n",
    "        windowed_frame = frame * window\n",
    "        spectrum = np.fft.rfft(windowed_frame)\n",
    "        magnitude = np.abs(spectrum)\n",
    "        phase = np.angle(spectrum)\n",
    "\n",
    "        # Subtract noise and ensure no negative values\n",
    "        magnitude = np.maximum(magnitude - noise_estimate * 1.5, 0.01 * magnitude)\n",
    "\n",
    "        # Reconstruct frame\n",
    "        enhanced_spectrum = magnitude * np.exp(1j * phase)\n",
    "        enhanced_frame = np.fft.irfft(enhanced_spectrum)\n",
    "\n",
    "        # Overlap-add\n",
    "        start = i * hop_size\n",
    "        end = start + frame_size\n",
    "        result[start:end] += enhanced_frame\n",
    "\n",
    "    # Normalize\n",
    "    result = result / np.max(np.abs(result))\n",
    "    return result\n",
    "\n",
    "# Function to apply Butterworth bandpass filter\n",
    "def apply_butter_bandpass(data, fs, lowcut, highcut, order=5):\n",
    "    \"\"\"Apply Butterworth bandpass filter\"\"\"\n",
    "    print(f\"Applying bandpass filter: {lowcut}-{highcut}Hz, order {order}\")\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    filtered_data = signal.filtfilt(b, a, data)\n",
    "    return filtered_data\n",
    "\n",
    "# Function to create spectrogram\n",
    "def create_spectrogram(data, fs, nperseg=256, noverlap=128, cmap='viridis'):\n",
    "    \"\"\"Create and return spectrogram of the data\"\"\"\n",
    "    print(\"Creating spectrogram\")\n",
    "    f, t, Sxx = signal.spectrogram(data, fs=fs, nperseg=nperseg, noverlap=noverlap)\n",
    "    return f, t, Sxx\n",
    "\n",
    "# Function to detect potential seismic events using energy\n",
    "def detect_seismic_events(data, fs, window_size=5.0, threshold_factor=20.0):\n",
    "    \"\"\"Detect potential seismic events based on energy threshold\"\"\"\n",
    "    print(\"Detecting potential seismic events\")\n",
    "    window_samples = int(window_size * fs)\n",
    "    energy = []\n",
    "\n",
    "    # Calculate energy in sliding windows\n",
    "    for i in range(0, len(data) - window_samples, window_samples // 2):\n",
    "        window = data[i:i+window_samples]\n",
    "        window_energy = np.sum(window**2) / len(window)\n",
    "        energy.append(window_energy)\n",
    "\n",
    "    # Set threshold as a factor of the median energy\n",
    "    energy = np.array(energy)\n",
    "    threshold = np.median(energy) * threshold_factor\n",
    "\n",
    "    # Find events that exceed threshold\n",
    "    events = []\n",
    "    in_event = False\n",
    "    event_start = 0\n",
    "\n",
    "    for i, e in enumerate(energy):\n",
    "        if e > threshold and not in_event:\n",
    "            in_event = True\n",
    "            event_start = i * (window_samples // 2) / fs\n",
    "        elif e <= threshold and in_event:\n",
    "            in_event = False\n",
    "            event_end = i * (window_samples // 2) / fs\n",
    "            events.append((event_start, event_end))\n",
    "\n",
    "    # Handle if we're still in an event at the end\n",
    "    if in_event:\n",
    "        event_end = len(data) / fs\n",
    "        events.append((event_start, event_end))\n",
    "\n",
    "    return events, energy, threshold\n",
    "\n",
    "# Main processing function\n",
    "def process_underwater_recording(data,original_fs, target_fs=50, low_pass=1.5, high_pass=0.6):\n",
    "    \"\"\"Process underwater recording to visualize seismic events\"\"\"\n",
    "    # Load data\n",
    "\n",
    "    print(f\"Original sampling rate: {original_fs}Hz\")\n",
    "    print(f\"Original data length: {len(data)} samples ({len(data)/original_fs:.2f} seconds)\")\n",
    "\n",
    "    # Downsample to 50Hz\n",
    "    downsampled_data, new_fs = downsample_audio(data, original_fs, target_fs)\n",
    "    print(f\"Downsampled data length: {len(downsampled_data)} samples ({len(downsampled_data)/new_fs:.2f} seconds)\")\n",
    "\n",
    "    # Apply dehazing\n",
    "    dehazed_data = dehaze_audio(downsampled_data, new_fs)\n",
    "\n",
    "    # Apply Butterworth bandpass filter\n",
    "    filtered_data = apply_butter_bandpass(dehazed_data, new_fs, high_pass, low_pass)\n",
    "\n",
    "    # Create spectrograms for comparison\n",
    "    f_orig, t_orig, Sxx_orig = create_spectrogram(downsampled_data, new_fs)\n",
    "    f_filtered, t_filtered, Sxx_filtered = create_spectrogram(filtered_data, new_fs)\n",
    "\n",
    "    # Detect potential seismic events\n",
    "    events, energy, threshold = detect_seismic_events(filtered_data, new_fs)\n",
    "\n",
    "    # Create custom colormap for better visualization (dark blue to light blue to white)\n",
    "    colors = [(0, 0, 0.5), (0, 0, 1), (0, 0.5, 1), (0, 1, 1), (1, 1, 1)]\n",
    "    positions = [0, 0.25, 0.5, 0.75, 1]\n",
    "    cmap_name = 'seismic_blue'\n",
    "    cm = LinearSegmentedColormap.from_list(cmap_name, list(zip(positions, colors)))\n",
    "\n",
    "    # Visualize the results\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Plot original waveform\n",
    "    plt.subplot(4, 1, 1)\n",
    "    plt.plot(np.arange(len(downsampled_data))/new_fs, downsampled_data)\n",
    "    plt.title('Original Signal (Downsampled to 50Hz)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "\n",
    "    # Plot filtered waveform with event markers\n",
    "    plt.subplot(4, 1, 2)\n",
    "    plt.plot(np.arange(len(filtered_data))/new_fs, filtered_data)\n",
    "    plt.title(f'Filtered Signal (Bandpass {high_pass}-{low_pass}Hz)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "\n",
    "    # Add markers for detected events\n",
    "    for event_start, event_end in events:\n",
    "        plt.axvspan(event_start, event_end, color='red', alpha=0.3)\n",
    "        plt.annotate('Event', xy=(event_start, max(filtered_data)*0.8),\n",
    "                    xytext=(event_start, max(filtered_data)),\n",
    "                    arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "\n",
    "    # Plot original spectrogram\n",
    "    plt.subplot(4, 1, 3)\n",
    "    plt.pcolormesh(t_orig, f_orig, 10 * np.log10(Sxx_orig + 1e-10), shading='gouraud', cmap=cm)\n",
    "    plt.title('Original Spectrogram')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.colorbar(label='Power/Frequency (dB/Hz)')\n",
    "    plt.ylim(0, 10)  # Limit frequency range for better visualization\n",
    "\n",
    "    # Plot filtered spectrogram\n",
    "    plt.subplot(4, 1, 4)\n",
    "    plt.pcolormesh(t_filtered, f_filtered, 10 * np.log10(Sxx_filtered + 1e-10), shading='gouraud', cmap=cm)\n",
    "    plt.title('Filtered Spectrogram')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.colorbar(label='Power/Frequency (dB/Hz)')\n",
    "    plt.ylim(0, 5)  # Limit frequency range for better visualization\n",
    "\n",
    "    # Add markers for detected events on spectrogram\n",
    "    for event_start, event_end in events:\n",
    "        plt.axvspan(event_start, event_end, color='red', alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Create a separate figure for event detection results\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    window_size = 1.0  # seconds\n",
    "    time_axis = np.arange(len(energy)) * (window_size/2)\n",
    "    plt.plot(time_axis, energy)\n",
    "    plt.axhline(threshold, color='r', linestyle='--', label='Threshold')\n",
    "    plt.title('Signal Energy for Event Detection')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Energy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Print detected events\n",
    "    print(\"/nDetected seismic events:\")\n",
    "    for i, (start, end) in enumerate(events):\n",
    "        print(f\"Event {i+1}: {start:.2f}s - {end:.2f}s (duration: {end-start:.2f}s)\")\n",
    "\n",
    "    # Save processed data if needed\n",
    "    # wavfile.write(\"filtered_underwater_recording.wav\", new_fs, (filtered_data * 32767).astype(np.int16))\n",
    "\n",
    "    plt.show()\n",
    "    return filtered_data, events\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual file path\n",
    "    file_path = \"underwater_recording.wav\"\n",
    "\n",
    "    # Process with the specific parameters\n",
    "    # Original frequency: 240Hz\n",
    "    # Target frequency: 50Hz\n",
    "    # Filter range: 0.6-1.5Hz\n",
    "    filtered_data, events = process_underwater_recording(\n",
    "        data,240,\n",
    "        target_fs=60,\n",
    "        low_pass=2.5,\n",
    "        high_pass=0.6\n",
    "    )"
   ],
   "id": "9d0d23d14be49329",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sampling rate: 240Hz\n",
      "Original data length: 143997 samples (599.99 seconds)\n",
      "Downsampling from 240Hz to 60Hz\n",
      "Downsampled data length: 36000 samples (600.00 seconds)\n",
      "Applying dehazing using spectral subtraction\n",
      "Applying bandpass filter: 0.6-2.5Hz, order 5\n",
      "Creating spectrogram\n",
      "Creating spectrogram\n",
      "Detecting potential seismic events\n",
      "/nDetected seismic events:\n",
      "Event 1: 300.00s - 317.50s (duration: 17.50s)\n",
      "Event 2: 320.00s - 357.50s (duration: 37.50s)\n",
      "Event 3: 365.00s - 377.50s (duration: 12.50s)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:34.420352Z",
     "start_time": "2025-03-10T18:35:34.366162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Downsample to 50Hz\n",
    "target_fs=120\n",
    "low_pass=2\n",
    "high_pass=0.06\n",
    "original_fs = 240\n",
    "\n",
    "downsampled_data, new_fs = downsample_audio(data, original_fs, target_fs)\n",
    "print(f\"Downsampled data length: {len(downsampled_data)} samples ({len(downsampled_data)/new_fs:.2f} seconds)\")\n",
    "\n",
    "# Apply dehazing\n",
    "dehazed_data = dehaze_audio(downsampled_data, target_fs)\n",
    "\n",
    "# Apply Butterworth bandpass filter\n",
    "filtered_data = apply_butter_bandpass(dehazed_data, target_fs, high_pass, low_pass)"
   ],
   "id": "aacf472d7485200",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling from 240Hz to 120Hz\n",
      "Downsampled data length: 71999 samples (599.99 seconds)\n",
      "Applying dehazing using spectral subtraction\n",
      "Applying bandpass filter: 0.06-2Hz, order 5\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:34.507506Z",
     "start_time": "2025-03-10T18:35:34.472584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%matplotlib qt\n",
    "# plt.plot(data,label='Original Signal')\n",
    "# plt.plot(downsampled_data,label='Downsampled Signal')\n",
    "t = np.arange(len(filtered_data))/30\n",
    "\n",
    "plt.plot(t,filtered_data,label='Filtered Signal')\n",
    "print(filtered_data)\n"
   ],
   "id": "8546d00699fe31f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan ... nan nan nan]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:34.756877Z",
     "start_time": "2025-03-10T18:35:34.619399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'audio_data' is your numpy array and fs = 240 Hz\n",
    "audio_segment = data # Take a segment for FFT (e.g., 10 seconds)\n",
    "\n",
    "fft_result = np.fft.fft(audio_segment)\n",
    "frequencies = np.fft.fftfreq(audio_segment.size, d=1/fs)\n",
    "magnitude_spectrum = np.abs(fft_result)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(frequencies[:audio_segment.size//2], magnitude_spectrum[:audio_segment.size//2]) # Plot positive frequencies\n",
    "plt.title('Frequency Spectrum of Audio Data (Example Segment)')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.xlim(0, fs/2) # Limit x-axis to Nyquist frequency\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "bacc5dc5e9e365d9",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:35.111141Z",
     "start_time": "2025-03-10T18:35:34.902334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    \"\"\"\n",
    "    Applies a bandpass filter to the audio data.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): Audio data.\n",
    "        lowcut (float): Lower cutoff frequency in Hz.\n",
    "        highcut (float): Upper cutoff frequency in Hz.\n",
    "        fs (float): Sampling rate of the audio data in Hz.\n",
    "        order (int): Order of the filter. Higher order filters have steeper\n",
    "                     roll-offs but may introduce more ringing.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Filtered audio data.\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    sos = butter(order, [low, high], btype='band', output='sos')\n",
    "    filtered_data = sosfiltfilt(sos, data)\n",
    "    return filtered_data\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'audio_data' is your numpy array of audio data and 'sampling_rate' is the sampling rate.\n",
    "# You'll need to define appropriate 'lowcut' and 'highcut' frequencies based on your P-wave characteristics and noise.\n",
    "# For example, let's assume P-waves are roughly in the range of 5-20 Hz (this is just an example, adjust accordingly!).\n",
    "sampling_rate = 240.0  # Example sampling rate, adjust to your actual rate\n",
    "lowcut_freq =5    # Lower cutoff frequency for bandpass filter\n",
    "highcut_freq =30 # Upper cutoff frequency for bandpass filter\n",
    "\n",
    "# Let's create some dummy audio data for demonstration\n",
    "duration = 2*60  # seconds\n",
    "time = np.arange(len(data))/sampling_rate\n",
    "# A signal with frequencies around 10Hz, plus some noise\n",
    "audio_data = data\n",
    "\n",
    "filtered_audio = bandpass_filter(audio_data, lowcut_freq, highcut_freq, sampling_rate)\n",
    "\n",
    "# Plotting original and filtered data for comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time, audio_data)\n",
    "plt.title('Original Audio Data')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(time, filtered_audio)\n",
    "plt.title(f'Bandpass Filtered Audio ({lowcut_freq}-{highcut_freq} Hz)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "8339c0c0188b9dc9",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:35.813386Z",
     "start_time": "2025-03-10T18:35:35.593313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.signal import wiener\n",
    "\n",
    "def deconvolve_wiener(data, noise_power=0.000001): # noise_power is a parameter to tune\n",
    "    \"\"\"\n",
    "    Applies Wiener deconvolution to the audio data.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): Audio data to be deconvolved.\n",
    "        noise_power (float): Estimated noise power relative to signal power.\n",
    "                             Adjust this based on your data's noise characteristics.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Deconvolved audio data.\n",
    "    \"\"\"\n",
    "    deconvolved_data = wiener(data, noise=noise_power)\n",
    "    return deconvolved_data\n",
    "\n",
    "# Example usage:\n",
    "# Apply deconvolution after filtering (or on original data, try both)\n",
    "deconvolved_audio = deconvolve_wiener(filtered_audio, noise_power=0.01) # Adjust noise_power\n",
    "\n",
    "# Plotting filtered and deconvolved data for comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time, filtered_audio)\n",
    "plt.title('Bandpass Filtered Audio')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(time, deconvolved_audio)\n",
    "plt.title('Deconvolved Audio (Wiener)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "103671b84bc072e9",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:36.510868Z",
     "start_time": "2025-03-10T18:35:36.483460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_amplitude(data):\n",
    "    max_amplitude = np.max(np.abs(data))\n",
    "    if max_amplitude > 0:\n",
    "        return data / max_amplitude\n",
    "    else:\n",
    "        return data # Avoid division by zero if data is all zeros\n",
    "\n",
    "normalized_audio = normalize_amplitude(deconvolved_audio) # Or stacked_audio, etc.\n",
    "plt.plot(time, normalized_audio)"
   ],
   "id": "fd18c35a1c8ab63d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x220fb11bb00>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:37.455199Z",
     "start_time": "2025-03-10T18:35:37.174265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy.signal import filtfilt, freqz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# High-pass filter coefficients (4th order Butterworth)\n",
    "a1 = np.array([1.0000, -3.9959, 5.9877, -3.9877, 0.9959], dtype=np.float64)\n",
    "b1 = np.array([0.9979, -3.9918, 5.9877, -3.9918, 0.9979], dtype=np.float64)\n",
    "\n",
    "# Low-pass filter coefficients (6th order Butterworth)\n",
    "a2 = np.array([1.0000, -5.7876, 13.9604, -17.9641, 13.0061, -5.0234, 0.8086], dtype=np.float64)\n",
    "b2 = np.array([3.8857e-10, 2.3314e-09, 5.8286e-09, 7.7714e-09,\n",
    "              5.8286e-09, 2.3314e-09, 3.8857e-10], dtype=np.float64)\n",
    "\n",
    "def apply_matlab_filters(data, fs):\n",
    "    \"\"\"Replicates MATLAB's filtering exactly using provided coefficients.\"\"\"\n",
    "    # MATLAB-style padding for filtfilt\n",
    "    filtered = filtfilt(b1, a1, data, padtype='constant', padlen=30)  # High-pass\n",
    "    filtered = filtfilt(b2, a2, filtered, padtype='constant', padlen=30)  # Low-pass\n",
    "    return filtered\n",
    "\n",
    "def plot_response(b, a, fs, title):\n",
    "    w, h = freqz(b, a, worN=2000, fs=fs)\n",
    "    plt.plot(w, 20 * np.log10(abs(h)))\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Amplitude [dB]')\n",
    "    plt.xlabel('Frequency [Hz]')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plot_response(b1, a1, fs=240, title='High-pass Filter Response (0.6Hz cutoff)')\n",
    "plt.subplot(2, 1, 2)\n",
    "plot_response(b2, a2, fs=240, title='Low-pass Filter Response (2.1Hz cutoff)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "5f0c02b4f8d30f1a",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:37.757108Z",
     "start_time": "2025-03-10T18:35:37.597119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_signal(data):\n",
    "    # Load data (replace with your data loading)\n",
    "    # Must use float64 for precision\n",
    "\n",
    "    # MATLAB-style processing\n",
    "    processed = apply_matlab_filters(data, fs=240)\n",
    "    print(processed)\n",
    "    # Plotting comparison\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(data, 'b', alpha=0.5, label='Original')\n",
    "    plt.plot(processed, 'r', label='Filtered (MATLAB coefficients)')\n",
    "    plt.legend()\n",
    "    plt.title('MATLAB vs Python Filtering Comparison')\n",
    "    plt.show()\n",
    "\n",
    "    return processed\n",
    "\n",
    "# Example usage:\n",
    "processed_data = process_signal(data)"
   ],
   "id": "4f22651c814b7897",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan ... nan nan nan]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:38.130587Z",
     "start_time": "2025-03-10T18:35:38.121937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime as dt\n",
    "cycle = 4012802424\n",
    "sple = 4004161980\n",
    "fstsp = 8640447\n",
    "start_date = dt.datetime.strptime(\"2018 01-16 07:30:50\",'%Y %m-%d %H:%M:%S')\n",
    "(sple/240.)\n"
   ],
   "id": "246039f5e8dc2c4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16684008.25"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:38.278592Z",
     "start_time": "2025-03-10T18:35:38.241126Z"
    }
   },
   "cell_type": "code",
   "source": "plt.close(\"all\")",
   "id": "45409248da82361a",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Estimate clock drift**\n",
   "id": "80c5ef5666f06840"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:44:27.838600Z",
     "start_time": "2025-03-10T18:44:27.813834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "name = 'NEAMS'\n",
    "File = f'C:/Users/Romain/PycharmProjects/toolbox/src/utils/detection/seismic_arrival_picking_tool/ui/{name}_2018_pointed.csv'\n",
    "\n",
    "data = pd.read_csv(File,parse_dates=['time', 'arrival_time', 'observed_arrival_time'], infer_datetime_format=True)\n",
    "\n",
    "\n",
    "# data.drop('nst',axis=1,inplace=True)\n",
    "data.dropna(how='any', inplace =True, ignore_index=True)\n",
    "data['time'] = pd.to_datetime(data['time'], utc=True, errors='coerce')\n",
    "ELAN_QC = [0.5,0.5,0.2,0.3,1,2,0.5,0.2,4,0.2,1,0.5,0.5,5,8,4,0.5,0.5,0.3,0.8,0.5,np.nan,1,0.5,0.2,0.3]\n",
    "WKER_QC = [0.2,2,0.2,1,0.5,0.1,0.5,0.3]\n",
    "NEAMS_QC = [0.5,0.5,0.1,1,0.3,0.4,0.2,0.3,1,0.4,0.2,1,0.4,0.2,0.2,0.1,0.3,0.4,0.5,0.5,0.1,0.5,0.2,1,0.5,0.5,0.2,0.2,0.5,0.5,0.5,0.5,0.8 ]\n",
    "error = {\"ELAN\": ELAN_QC, \"WKER2\": WKER_QC, \"NEAMS\": NEAMS_QC}\n",
    "sig = np.sqrt(np.power(2.5,2)+np.power(error[name],2))\n",
    "data[\"arrival_uncertainty\"] = pd.Series(sig, name=\"arrival_uncertainty\")\n",
    "data.dropna(how='any', inplace =True, ignore_index=True)\n",
    "# data['observed_arrival_time'] -= timedelta(minutes=10)\n",
    "# data.to_csv(File)"
   ],
   "id": "65a13f840a6bd448",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Romain\\AppData\\Local\\Temp\\ipykernel_3136\\2539290049.py:10: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  data = pd.read_csv(File,parse_dates=['time', 'arrival_time', 'observed_arrival_time'], infer_datetime_format=True)\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:44:34.463014Z",
     "start_time": "2025-03-10T18:44:34.456474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data[\"time_diff\"] = (data['arrival_time'] - data['observed_arrival_time'])\n",
    "data[\"time_diff\"] = data[\"time_diff\"].dt.total_seconds()\n",
    "data[\"arrival_uncertainty\"] = 2."
   ],
   "id": "d2941a79344b9dba",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "550bd199c3da3302"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:44:37.641024Z",
     "start_time": "2025-03-10T18:44:37.617846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "travel_time_ELAN = pd.read_csv(f\"C:/Users/Romain/PycharmProjects/Sea_sound_toolbox/data/2018_{name}_travel_times.csv\")\n",
    "#adding travel time from bottom to hydrophone\n",
    "#C:/Users/Romain/PycharmProjects/Sea_sound_toolbox/data/2018_NEAMS_travel_times.csv\n",
    "data['month'] = data['time'].dt.month\n",
    "data['arrival_time'] += pd.to_timedelta(\n",
    "    data['month'].map(travel_time_ELAN.set_index('month')['travel_time']),\n",
    "    unit='s'\n",
    ")"
   ],
   "id": "a628b17272e3f954",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:44:46.881247Z",
     "start_time": "2025-03-10T18:44:46.824024Z"
    }
   },
   "cell_type": "code",
   "source": "data",
   "id": "6af2bde95962f2ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Unnamed: 0                             time  latitude  longitude   depth  \\\n",
       "0            0 2018-02-09 11:43:56.760000+00:00  -17.8709  -178.6605  556.91   \n",
       "1            1 2018-03-08 17:39:51.100000+00:00   -4.3762   153.1996   22.86   \n",
       "2            2 2018-03-24 11:23:32.050000+00:00   -5.4959   151.4971   33.00   \n",
       "3            3 2018-03-25 20:14:47.690000+00:00   -6.6343   129.8172  169.00   \n",
       "4            4 2018-03-26 09:51:00.430000+00:00   -5.5024   151.4025   40.00   \n",
       "5            5 2018-03-29 21:25:36.790000+00:00   -5.5321   151.4999   35.00   \n",
       "6            6 2018-04-02 05:57:35.680000+00:00  -24.7190  -176.8865   92.00   \n",
       "7            7 2018-04-02 13:40:34.840000+00:00  -20.6588   -63.0058  559.00   \n",
       "8            8 2018-05-09 10:41:45.910000+00:00   36.9942    71.3822  116.00   \n",
       "9            9 2018-05-18 01:45:31.460000+00:00  -34.5886  -178.4143   11.00   \n",
       "10          10 2018-06-21 21:13:32.660000+00:00  -17.7905   168.0568   28.00   \n",
       "11          11 2018-07-13 09:46:49.070000+00:00  -18.9279   169.0467  167.00   \n",
       "12          12 2018-07-17 07:02:53.020000+00:00  -11.5936   166.4320   37.96   \n",
       "13          13 2018-07-28 17:07:23.380000+00:00   -7.1039   122.7263  578.16   \n",
       "14          14 2018-07-28 22:47:38.740000+00:00   -8.2395   116.5080   14.00   \n",
       "15          15 2018-08-05 11:46:38.630000+00:00   -8.2581   116.4375   34.00   \n",
       "16          16 2018-08-17 15:35:01.890000+00:00   -7.3718   119.8017  529.00   \n",
       "17          17 2018-08-19 00:19:40.670000+00:00  -18.1125  -178.1530  600.00   \n",
       "18          18 2018-08-19 04:28:58.700000+00:00  -16.9783  -178.0332  415.60   \n",
       "19          19 2018-09-06 15:49:18.710000+00:00  -18.4743   179.3502  670.81   \n",
       "20          20 2018-09-08 07:16:49.620000+00:00    7.2377   126.4779   10.00   \n",
       "21          21 2018-09-10 04:19:02.630000+00:00  -31.7447  -179.3728  115.00   \n",
       "22          22 2018-09-16 21:11:48.820000+00:00  -25.4150   178.1991  576.00   \n",
       "23          23 2018-10-10 20:48:20.100000+00:00   -5.7012   151.2046   39.00   \n",
       "24          24 2018-10-10 22:00:34.500000+00:00   -4.9624   151.7231  121.00   \n",
       "25          25 2018-11-18 20:25:46.590000+00:00  -17.8735  -178.9273  540.00   \n",
       "26          26 2018-11-25 16:37:32.830000+00:00   34.3609    45.7443   18.00   \n",
       "27          27 2018-12-05 04:18:08.420000+00:00  -21.9496   169.4266   10.00   \n",
       "28          28 2018-12-11 02:26:29.420000+00:00  -58.5446   -26.3856  133.00   \n",
       "29          29 2018-12-16 09:42:37.200000+00:00   -3.9226   140.2323   61.97   \n",
       "30          30 2018-12-22 14:25:01.180000+00:00  -13.4000   166.8151   42.00   \n",
       "31          31 2018-12-23 23:08:43.440000+00:00  -20.2855  -175.0710  113.00   \n",
       "32          32 2018-12-29 03:39:09.740000+00:00    5.8983   126.9209   60.21   \n",
       "\n",
       "    mag magType   gap   dmin   rms  ...  phase  travel_time  \\\n",
       "0   6.0     mww  35.0  7.704  0.90  ...      P   708.063557   \n",
       "1   6.8     mww  16.0  1.049  1.05  ...      P   673.772514   \n",
       "2   6.3     mww  19.0  5.361  0.95  ...      P   659.794798   \n",
       "3   6.4     mww  13.0  1.988  1.09  ...      P   517.305760   \n",
       "4   6.7     mww  15.0  1.507  1.18  ...      P   658.433871   \n",
       "5   6.9     mww  18.0  1.487  1.02  ...      P   659.404282   \n",
       "6   6.1     mww  20.0  4.603  1.15  ...      P   745.378921   \n",
       "7   6.8     mww  16.0  5.320  0.99  ...  PKIKP  1064.575853   \n",
       "8   6.2     mww  17.0  0.578  1.10  ...      P   655.659107   \n",
       "9   6.1     mww  19.0  3.982  0.82  ...      P   722.397664   \n",
       "10  6.1     mww  14.0  3.069  1.27  ...      P   707.363884   \n",
       "11  6.4     mww  19.0  2.505  0.96  ...      P   692.957926   \n",
       "12  6.0     mww  43.0  6.726  0.88  ...      P   715.579254   \n",
       "13  6.0     mww  19.0  1.597  1.31  ...      P   438.345935   \n",
       "14  6.4     mww  14.0  2.342  1.15  ...      P   443.688862   \n",
       "15  6.9     mww  15.0  2.271  1.05  ...      P   440.343924   \n",
       "16  6.5     mww  23.0  2.719  0.98  ...      P   422.880874   \n",
       "17  8.2     mww  13.0  3.630  0.79  ...      P   705.492763   \n",
       "18  6.4      mb  17.0  3.814  0.95  ...      P   725.874397   \n",
       "19  7.9     mww  12.0  1.431  1.07  ...      P   689.063594   \n",
       "20  6.2     mww  30.0  0.907  0.92  ...      P   583.297871   \n",
       "21  6.9     mww  18.0  2.785  0.97  ...      P   713.784604   \n",
       "22  6.5     mww  18.0  5.139  0.75  ...      P   674.752230   \n",
       "23  7.0     mww  18.0  1.778  1.10  ...      P   656.843876   \n",
       "24  6.2     mww  12.0  0.883  0.96  ...      P   652.920666   \n",
       "25  6.8     mww  39.0  2.879  1.30  ...      P   708.588117   \n",
       "26  6.3     mww  22.0  0.754  0.86  ...      P   698.992995   \n",
       "27  7.5     mww  18.0  2.405  0.74  ...      P   705.126117   \n",
       "28  7.1     mww  20.0  7.043  0.92  ...      P   673.310196   \n",
       "29  6.1     mww  14.0  7.364  0.93  ...      P   600.597764   \n",
       "30  6.0     mww  33.0  2.069  1.11  ...      P   711.890147   \n",
       "31  6.4     mww  20.0  4.993  0.89  ...      P   761.455537   \n",
       "32  7.0     mww  21.0  1.769  1.45  ...      P   572.353901   \n",
       "\n",
       "                          arrival_time distance_deg candidate  \\\n",
       "0  2018-02-09 11:55:46.041848611+00:00    87.336078      True   \n",
       "1  2018-03-08 17:51:06.090807269+00:00    70.665420      True   \n",
       "2  2018-03-24 11:34:33.063091201+00:00    68.633734      True   \n",
       "3  2018-03-25 20:23:26.214052678+00:00    50.043337      True   \n",
       "4  2018-03-26 10:02:00.082164144+00:00    68.550296      True   \n",
       "5  2018-03-29 21:36:37.412574939+00:00    68.617020      True   \n",
       "6  2018-04-02 06:10:02.277218316+00:00    85.049565      True   \n",
       "7  2018-04-02 13:58:20.634149942+00:00   118.559320      True   \n",
       "8  2018-05-09 10:52:42.787420909+00:00    69.461404      True   \n",
       "9  2018-05-18 01:57:35.075977673+00:00    78.727242      True   \n",
       "10 2018-06-21 21:25:21.242277497+00:00    76.508282      True   \n",
       "11 2018-07-13 09:58:23.246315177+00:00    76.772837      True   \n",
       "12 2018-07-17 07:14:49.817642979+00:00    78.217486      True   \n",
       "13 2018-07-28 17:14:42.944323863+00:00    44.172575      True   \n",
       "14 2018-07-28 22:55:03.647251080+00:00    38.736412      True   \n",
       "15 2018-08-05 11:54:00.192328911+00:00    38.671946      True   \n",
       "16 2018-08-17 15:42:05.989279212+00:00    41.768054      True   \n",
       "17 2018-08-19 00:31:27.381167869+00:00    87.613652      True   \n",
       "18 2018-08-19 04:41:05.792801924+00:00    88.320443      True   \n",
       "19 2018-09-06 16:00:48.991953752+00:00    85.414340      True   \n",
       "20 2018-09-08 07:26:34.136230778+00:00    56.649048      True   \n",
       "21 2018-09-10 04:30:57.632964389+00:00    79.491848      True   \n",
       "22 2018-09-16 21:23:04.790590321+00:00    80.895409      True   \n",
       "23 2018-10-10 20:59:18.162251968+00:00    68.278142      True   \n",
       "24 2018-10-10 22:11:28.639041718+00:00    69.106686      True   \n",
       "25 2018-11-18 20:37:36.396510805+00:00    87.120191      True   \n",
       "26 2018-11-25 16:49:13.041389130+00:00    74.785720      True   \n",
       "27 2018-12-05 04:29:54.764521195+00:00    75.622360      True   \n",
       "28 2018-12-11 02:37:43.948600311+00:00    72.702104      True   \n",
       "29 2018-12-16 09:52:39.016168007+00:00    60.075242      True   \n",
       "30 2018-12-22 14:36:54.288550583+00:00    77.636059      True   \n",
       "31 2018-12-23 23:21:26.113940552+00:00    88.872744      True   \n",
       "32 2018-12-29 03:48:43.312305241+00:00    56.007875      True   \n",
       "\n",
       "                 predicted_arrival_time               observed_arrival_time  \\\n",
       "0   2018-02-09 12:05:44.823556611+00:00 2018-02-09 11:55:44.825634336+00:00   \n",
       "1   2018-03-08 18:01:04.872514269+00:00 2018-03-08 17:51:06.877507200+00:00   \n",
       "2   2018-03-24 11:44:31.844798201+00:00 2018-03-24 11:34:33.849189312+00:00   \n",
       "3   2018-03-25 20:33:24.995759678+00:00 2018-03-25 20:23:27.106314536+00:00   \n",
       "4   2018-03-26 10:11:58.863871144+00:00 2018-03-26 10:02:02.871238130+00:00   \n",
       "5   2018-03-29 21:46:36.194281939+00:00 2018-03-29 21:36:37.102910575+00:00   \n",
       "6   2018-04-02 06:20:01.058921316+00:00 2018-04-02 06:10:04.262463822+00:00   \n",
       "7   2018-04-02 14:08:19.415852942+00:00 2018-04-02 13:58:24.474173382+00:00   \n",
       "8   2018-05-09 11:02:41.569106909+00:00 2018-05-09 10:52:40.603109442+00:00   \n",
       "9   2018-05-18 02:07:33.857663673+00:00 2018-05-18 01:57:38.507276787+00:00   \n",
       "10  2018-06-21 21:35:20.023884497+00:00 2018-06-21 21:25:24.199259104+00:00   \n",
       "11  2018-07-13 10:08:22.027926177+00:00 2018-07-13 09:58:25.186724857+00:00   \n",
       "12  2018-07-17 07:24:48.599253979+00:00 2018-07-17 07:14:48.044545197+00:00   \n",
       "13  2018-07-28 17:24:41.725934863+00:00 2018-07-28 17:14:45.280886551+00:00   \n",
       "14  2018-07-28 23:05:02.428862080+00:00 2018-07-28 22:55:05.326742854+00:00   \n",
       "15  2018-08-05 12:03:58.973923911+00:00 2018-08-05 11:54:02.493650122+00:00   \n",
       "16  2018-08-17 15:52:04.770874212+00:00 2018-08-17 15:42:08.917356821+00:00   \n",
       "17  2018-08-19 00:41:26.162762869+00:00 2018-08-19 00:31:29.511866672+00:00   \n",
       "18  2018-08-19 04:51:04.574396924+00:00 2018-08-19 04:41:08.106831262+00:00   \n",
       "19  2018-09-06 16:10:47.773593752+00:00 2018-09-06 16:00:52.232637516+00:00   \n",
       "20  2018-09-08 07:36:32.917870778+00:00 2018-09-08 07:26:36.043804774+00:00   \n",
       "21  2018-09-10 04:40:56.414604389+00:00 2018-09-10 04:31:00.057842448+00:00   \n",
       "22  2018-09-16 21:33:03.572230321+00:00 2018-09-16 21:23:12.801739534+00:00   \n",
       "23  2018-10-10 21:09:16.943875968+00:00 2018-10-10 20:59:22.401348525+00:00   \n",
       "24  2018-10-10 22:21:27.420665718+00:00 2018-10-10 22:11:31.674853980+00:00   \n",
       "25  2018-11-18 20:47:35.178116805+00:00 2018-11-18 20:37:40.090579272+00:00   \n",
       "26  2018-11-25 16:59:11.822995130+00:00 2018-11-25 16:49:18.413045080+00:00   \n",
       "27  2018-12-05 04:39:53.546117195+00:00 2018-12-05 04:29:58.844580156+00:00   \n",
       "28  2018-12-11 02:47:42.730196311+00:00 2018-12-11 02:37:48.012876064+00:00   \n",
       "29  2018-12-16 10:02:37.797764007+00:00 2018-12-16 09:52:42.905439236+00:00   \n",
       "30  2018-12-22 14:46:53.070146583+00:00 2018-12-22 14:36:57.580297772+00:00   \n",
       "31  2018-12-23 23:31:24.895536552+00:00 2018-12-23 23:21:29.117955920+00:00   \n",
       "32  2018-12-29 03:58:42.093901241+00:00 2018-12-29 03:48:47.688853392+00:00   \n",
       "\n",
       "    arrival_uncertainty  time_diff month  \n",
       "0                   2.0  -0.002078     2  \n",
       "1                   2.0  -2.004993     3  \n",
       "2                   2.0  -2.004391     3  \n",
       "3                   2.0  -2.110555     3  \n",
       "4                   2.0  -4.007367     3  \n",
       "5                   2.0  -0.908629     3  \n",
       "6                   2.0  -3.203543     4  \n",
       "7                   2.0  -5.058320     4  \n",
       "8                   2.0   0.965997     5  \n",
       "9                   2.0  -4.649613     5  \n",
       "10                  2.0  -4.175375     6  \n",
       "11                  2.0  -3.158799     7  \n",
       "12                  2.0   0.554709     7  \n",
       "13                  2.0  -3.554952     7  \n",
       "14                  2.0  -2.897881     7  \n",
       "15                  2.0  -3.519726     8  \n",
       "16                  2.0  -4.146483     8  \n",
       "17                  2.0  -3.349104     8  \n",
       "18                  2.0  -3.532434     8  \n",
       "19                  2.0  -4.459044     9  \n",
       "20                  2.0  -3.125934     9  \n",
       "21                  2.0  -3.643238     9  \n",
       "22                  2.0  -9.229509     9  \n",
       "23                  2.0  -5.457473    10  \n",
       "24                  2.0  -4.254188    10  \n",
       "25                  2.0  -4.912462    11  \n",
       "26                  2.0  -6.590050    11  \n",
       "27                  2.0  -5.298463    12  \n",
       "28                  2.0  -5.282680    12  \n",
       "29                  2.0  -5.107675    12  \n",
       "30                  2.0  -4.510151    12  \n",
       "31                  2.0  -4.222419    12  \n",
       "32                  2.0  -5.594952    12  \n",
       "\n",
       "[33 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>phase</th>\n",
       "      <th>travel_time</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>distance_deg</th>\n",
       "      <th>candidate</th>\n",
       "      <th>predicted_arrival_time</th>\n",
       "      <th>observed_arrival_time</th>\n",
       "      <th>arrival_uncertainty</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-09 11:43:56.760000+00:00</td>\n",
       "      <td>-17.8709</td>\n",
       "      <td>-178.6605</td>\n",
       "      <td>556.91</td>\n",
       "      <td>6.0</td>\n",
       "      <td>mww</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.704</td>\n",
       "      <td>0.90</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>708.063557</td>\n",
       "      <td>2018-02-09 11:55:46.041848611+00:00</td>\n",
       "      <td>87.336078</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-02-09 12:05:44.823556611+00:00</td>\n",
       "      <td>2018-02-09 11:55:44.825634336+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.002078</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-08 17:39:51.100000+00:00</td>\n",
       "      <td>-4.3762</td>\n",
       "      <td>153.1996</td>\n",
       "      <td>22.86</td>\n",
       "      <td>6.8</td>\n",
       "      <td>mww</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.049</td>\n",
       "      <td>1.05</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>673.772514</td>\n",
       "      <td>2018-03-08 17:51:06.090807269+00:00</td>\n",
       "      <td>70.665420</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-03-08 18:01:04.872514269+00:00</td>\n",
       "      <td>2018-03-08 17:51:06.877507200+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.004993</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-03-24 11:23:32.050000+00:00</td>\n",
       "      <td>-5.4959</td>\n",
       "      <td>151.4971</td>\n",
       "      <td>33.00</td>\n",
       "      <td>6.3</td>\n",
       "      <td>mww</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.361</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>659.794798</td>\n",
       "      <td>2018-03-24 11:34:33.063091201+00:00</td>\n",
       "      <td>68.633734</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-03-24 11:44:31.844798201+00:00</td>\n",
       "      <td>2018-03-24 11:34:33.849189312+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.004391</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-03-25 20:14:47.690000+00:00</td>\n",
       "      <td>-6.6343</td>\n",
       "      <td>129.8172</td>\n",
       "      <td>169.00</td>\n",
       "      <td>6.4</td>\n",
       "      <td>mww</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.988</td>\n",
       "      <td>1.09</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>517.305760</td>\n",
       "      <td>2018-03-25 20:23:26.214052678+00:00</td>\n",
       "      <td>50.043337</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-03-25 20:33:24.995759678+00:00</td>\n",
       "      <td>2018-03-25 20:23:27.106314536+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.110555</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-03-26 09:51:00.430000+00:00</td>\n",
       "      <td>-5.5024</td>\n",
       "      <td>151.4025</td>\n",
       "      <td>40.00</td>\n",
       "      <td>6.7</td>\n",
       "      <td>mww</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.507</td>\n",
       "      <td>1.18</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>658.433871</td>\n",
       "      <td>2018-03-26 10:02:00.082164144+00:00</td>\n",
       "      <td>68.550296</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-03-26 10:11:58.863871144+00:00</td>\n",
       "      <td>2018-03-26 10:02:02.871238130+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.007367</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-03-29 21:25:36.790000+00:00</td>\n",
       "      <td>-5.5321</td>\n",
       "      <td>151.4999</td>\n",
       "      <td>35.00</td>\n",
       "      <td>6.9</td>\n",
       "      <td>mww</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.487</td>\n",
       "      <td>1.02</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>659.404282</td>\n",
       "      <td>2018-03-29 21:36:37.412574939+00:00</td>\n",
       "      <td>68.617020</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-03-29 21:46:36.194281939+00:00</td>\n",
       "      <td>2018-03-29 21:36:37.102910575+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.908629</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-04-02 05:57:35.680000+00:00</td>\n",
       "      <td>-24.7190</td>\n",
       "      <td>-176.8865</td>\n",
       "      <td>92.00</td>\n",
       "      <td>6.1</td>\n",
       "      <td>mww</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.603</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>745.378921</td>\n",
       "      <td>2018-04-02 06:10:02.277218316+00:00</td>\n",
       "      <td>85.049565</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-04-02 06:20:01.058921316+00:00</td>\n",
       "      <td>2018-04-02 06:10:04.262463822+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.203543</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-04-02 13:40:34.840000+00:00</td>\n",
       "      <td>-20.6588</td>\n",
       "      <td>-63.0058</td>\n",
       "      <td>559.00</td>\n",
       "      <td>6.8</td>\n",
       "      <td>mww</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.320</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>PKIKP</td>\n",
       "      <td>1064.575853</td>\n",
       "      <td>2018-04-02 13:58:20.634149942+00:00</td>\n",
       "      <td>118.559320</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-04-02 14:08:19.415852942+00:00</td>\n",
       "      <td>2018-04-02 13:58:24.474173382+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.058320</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2018-05-09 10:41:45.910000+00:00</td>\n",
       "      <td>36.9942</td>\n",
       "      <td>71.3822</td>\n",
       "      <td>116.00</td>\n",
       "      <td>6.2</td>\n",
       "      <td>mww</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.578</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>655.659107</td>\n",
       "      <td>2018-05-09 10:52:42.787420909+00:00</td>\n",
       "      <td>69.461404</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-05-09 11:02:41.569106909+00:00</td>\n",
       "      <td>2018-05-09 10:52:40.603109442+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.965997</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2018-05-18 01:45:31.460000+00:00</td>\n",
       "      <td>-34.5886</td>\n",
       "      <td>-178.4143</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6.1</td>\n",
       "      <td>mww</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.982</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>722.397664</td>\n",
       "      <td>2018-05-18 01:57:35.075977673+00:00</td>\n",
       "      <td>78.727242</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-05-18 02:07:33.857663673+00:00</td>\n",
       "      <td>2018-05-18 01:57:38.507276787+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.649613</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-06-21 21:13:32.660000+00:00</td>\n",
       "      <td>-17.7905</td>\n",
       "      <td>168.0568</td>\n",
       "      <td>28.00</td>\n",
       "      <td>6.1</td>\n",
       "      <td>mww</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.069</td>\n",
       "      <td>1.27</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>707.363884</td>\n",
       "      <td>2018-06-21 21:25:21.242277497+00:00</td>\n",
       "      <td>76.508282</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-06-21 21:35:20.023884497+00:00</td>\n",
       "      <td>2018-06-21 21:25:24.199259104+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.175375</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2018-07-13 09:46:49.070000+00:00</td>\n",
       "      <td>-18.9279</td>\n",
       "      <td>169.0467</td>\n",
       "      <td>167.00</td>\n",
       "      <td>6.4</td>\n",
       "      <td>mww</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.505</td>\n",
       "      <td>0.96</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>692.957926</td>\n",
       "      <td>2018-07-13 09:58:23.246315177+00:00</td>\n",
       "      <td>76.772837</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-07-13 10:08:22.027926177+00:00</td>\n",
       "      <td>2018-07-13 09:58:25.186724857+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.158799</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2018-07-17 07:02:53.020000+00:00</td>\n",
       "      <td>-11.5936</td>\n",
       "      <td>166.4320</td>\n",
       "      <td>37.96</td>\n",
       "      <td>6.0</td>\n",
       "      <td>mww</td>\n",
       "      <td>43.0</td>\n",
       "      <td>6.726</td>\n",
       "      <td>0.88</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>715.579254</td>\n",
       "      <td>2018-07-17 07:14:49.817642979+00:00</td>\n",
       "      <td>78.217486</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-07-17 07:24:48.599253979+00:00</td>\n",
       "      <td>2018-07-17 07:14:48.044545197+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.554709</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2018-07-28 17:07:23.380000+00:00</td>\n",
       "      <td>-7.1039</td>\n",
       "      <td>122.7263</td>\n",
       "      <td>578.16</td>\n",
       "      <td>6.0</td>\n",
       "      <td>mww</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.597</td>\n",
       "      <td>1.31</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>438.345935</td>\n",
       "      <td>2018-07-28 17:14:42.944323863+00:00</td>\n",
       "      <td>44.172575</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-07-28 17:24:41.725934863+00:00</td>\n",
       "      <td>2018-07-28 17:14:45.280886551+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.554952</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2018-07-28 22:47:38.740000+00:00</td>\n",
       "      <td>-8.2395</td>\n",
       "      <td>116.5080</td>\n",
       "      <td>14.00</td>\n",
       "      <td>6.4</td>\n",
       "      <td>mww</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.342</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>443.688862</td>\n",
       "      <td>2018-07-28 22:55:03.647251080+00:00</td>\n",
       "      <td>38.736412</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-07-28 23:05:02.428862080+00:00</td>\n",
       "      <td>2018-07-28 22:55:05.326742854+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.897881</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2018-08-05 11:46:38.630000+00:00</td>\n",
       "      <td>-8.2581</td>\n",
       "      <td>116.4375</td>\n",
       "      <td>34.00</td>\n",
       "      <td>6.9</td>\n",
       "      <td>mww</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.271</td>\n",
       "      <td>1.05</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>440.343924</td>\n",
       "      <td>2018-08-05 11:54:00.192328911+00:00</td>\n",
       "      <td>38.671946</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-08-05 12:03:58.973923911+00:00</td>\n",
       "      <td>2018-08-05 11:54:02.493650122+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.519726</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2018-08-17 15:35:01.890000+00:00</td>\n",
       "      <td>-7.3718</td>\n",
       "      <td>119.8017</td>\n",
       "      <td>529.00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>mww</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.719</td>\n",
       "      <td>0.98</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>422.880874</td>\n",
       "      <td>2018-08-17 15:42:05.989279212+00:00</td>\n",
       "      <td>41.768054</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-08-17 15:52:04.770874212+00:00</td>\n",
       "      <td>2018-08-17 15:42:08.917356821+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.146483</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2018-08-19 00:19:40.670000+00:00</td>\n",
       "      <td>-18.1125</td>\n",
       "      <td>-178.1530</td>\n",
       "      <td>600.00</td>\n",
       "      <td>8.2</td>\n",
       "      <td>mww</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.630</td>\n",
       "      <td>0.79</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>705.492763</td>\n",
       "      <td>2018-08-19 00:31:27.381167869+00:00</td>\n",
       "      <td>87.613652</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-08-19 00:41:26.162762869+00:00</td>\n",
       "      <td>2018-08-19 00:31:29.511866672+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.349104</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2018-08-19 04:28:58.700000+00:00</td>\n",
       "      <td>-16.9783</td>\n",
       "      <td>-178.0332</td>\n",
       "      <td>415.60</td>\n",
       "      <td>6.4</td>\n",
       "      <td>mb</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.814</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>725.874397</td>\n",
       "      <td>2018-08-19 04:41:05.792801924+00:00</td>\n",
       "      <td>88.320443</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-08-19 04:51:04.574396924+00:00</td>\n",
       "      <td>2018-08-19 04:41:08.106831262+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.532434</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2018-09-06 15:49:18.710000+00:00</td>\n",
       "      <td>-18.4743</td>\n",
       "      <td>179.3502</td>\n",
       "      <td>670.81</td>\n",
       "      <td>7.9</td>\n",
       "      <td>mww</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.431</td>\n",
       "      <td>1.07</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>689.063594</td>\n",
       "      <td>2018-09-06 16:00:48.991953752+00:00</td>\n",
       "      <td>85.414340</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-09-06 16:10:47.773593752+00:00</td>\n",
       "      <td>2018-09-06 16:00:52.232637516+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.459044</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-09-08 07:16:49.620000+00:00</td>\n",
       "      <td>7.2377</td>\n",
       "      <td>126.4779</td>\n",
       "      <td>10.00</td>\n",
       "      <td>6.2</td>\n",
       "      <td>mww</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.92</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>583.297871</td>\n",
       "      <td>2018-09-08 07:26:34.136230778+00:00</td>\n",
       "      <td>56.649048</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-09-08 07:36:32.917870778+00:00</td>\n",
       "      <td>2018-09-08 07:26:36.043804774+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.125934</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2018-09-10 04:19:02.630000+00:00</td>\n",
       "      <td>-31.7447</td>\n",
       "      <td>-179.3728</td>\n",
       "      <td>115.00</td>\n",
       "      <td>6.9</td>\n",
       "      <td>mww</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.785</td>\n",
       "      <td>0.97</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>713.784604</td>\n",
       "      <td>2018-09-10 04:30:57.632964389+00:00</td>\n",
       "      <td>79.491848</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-09-10 04:40:56.414604389+00:00</td>\n",
       "      <td>2018-09-10 04:31:00.057842448+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.643238</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-09-16 21:11:48.820000+00:00</td>\n",
       "      <td>-25.4150</td>\n",
       "      <td>178.1991</td>\n",
       "      <td>576.00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>mww</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.139</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>674.752230</td>\n",
       "      <td>2018-09-16 21:23:04.790590321+00:00</td>\n",
       "      <td>80.895409</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-09-16 21:33:03.572230321+00:00</td>\n",
       "      <td>2018-09-16 21:23:12.801739534+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.229509</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>2018-10-10 20:48:20.100000+00:00</td>\n",
       "      <td>-5.7012</td>\n",
       "      <td>151.2046</td>\n",
       "      <td>39.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>mww</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.778</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>656.843876</td>\n",
       "      <td>2018-10-10 20:59:18.162251968+00:00</td>\n",
       "      <td>68.278142</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-10-10 21:09:16.943875968+00:00</td>\n",
       "      <td>2018-10-10 20:59:22.401348525+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.457473</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2018-10-10 22:00:34.500000+00:00</td>\n",
       "      <td>-4.9624</td>\n",
       "      <td>151.7231</td>\n",
       "      <td>121.00</td>\n",
       "      <td>6.2</td>\n",
       "      <td>mww</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.96</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>652.920666</td>\n",
       "      <td>2018-10-10 22:11:28.639041718+00:00</td>\n",
       "      <td>69.106686</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-10-10 22:21:27.420665718+00:00</td>\n",
       "      <td>2018-10-10 22:11:31.674853980+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.254188</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>2018-11-18 20:25:46.590000+00:00</td>\n",
       "      <td>-17.8735</td>\n",
       "      <td>-178.9273</td>\n",
       "      <td>540.00</td>\n",
       "      <td>6.8</td>\n",
       "      <td>mww</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.879</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>708.588117</td>\n",
       "      <td>2018-11-18 20:37:36.396510805+00:00</td>\n",
       "      <td>87.120191</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-11-18 20:47:35.178116805+00:00</td>\n",
       "      <td>2018-11-18 20:37:40.090579272+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.912462</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2018-11-25 16:37:32.830000+00:00</td>\n",
       "      <td>34.3609</td>\n",
       "      <td>45.7443</td>\n",
       "      <td>18.00</td>\n",
       "      <td>6.3</td>\n",
       "      <td>mww</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.86</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>698.992995</td>\n",
       "      <td>2018-11-25 16:49:13.041389130+00:00</td>\n",
       "      <td>74.785720</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-11-25 16:59:11.822995130+00:00</td>\n",
       "      <td>2018-11-25 16:49:18.413045080+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.590050</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2018-12-05 04:18:08.420000+00:00</td>\n",
       "      <td>-21.9496</td>\n",
       "      <td>169.4266</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7.5</td>\n",
       "      <td>mww</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.405</td>\n",
       "      <td>0.74</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>705.126117</td>\n",
       "      <td>2018-12-05 04:29:54.764521195+00:00</td>\n",
       "      <td>75.622360</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-05 04:39:53.546117195+00:00</td>\n",
       "      <td>2018-12-05 04:29:58.844580156+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.298463</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2018-12-11 02:26:29.420000+00:00</td>\n",
       "      <td>-58.5446</td>\n",
       "      <td>-26.3856</td>\n",
       "      <td>133.00</td>\n",
       "      <td>7.1</td>\n",
       "      <td>mww</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.043</td>\n",
       "      <td>0.92</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>673.310196</td>\n",
       "      <td>2018-12-11 02:37:43.948600311+00:00</td>\n",
       "      <td>72.702104</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-11 02:47:42.730196311+00:00</td>\n",
       "      <td>2018-12-11 02:37:48.012876064+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.282680</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2018-12-16 09:42:37.200000+00:00</td>\n",
       "      <td>-3.9226</td>\n",
       "      <td>140.2323</td>\n",
       "      <td>61.97</td>\n",
       "      <td>6.1</td>\n",
       "      <td>mww</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.364</td>\n",
       "      <td>0.93</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>600.597764</td>\n",
       "      <td>2018-12-16 09:52:39.016168007+00:00</td>\n",
       "      <td>60.075242</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-16 10:02:37.797764007+00:00</td>\n",
       "      <td>2018-12-16 09:52:42.905439236+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.107675</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>2018-12-22 14:25:01.180000+00:00</td>\n",
       "      <td>-13.4000</td>\n",
       "      <td>166.8151</td>\n",
       "      <td>42.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>mww</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.069</td>\n",
       "      <td>1.11</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>711.890147</td>\n",
       "      <td>2018-12-22 14:36:54.288550583+00:00</td>\n",
       "      <td>77.636059</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-22 14:46:53.070146583+00:00</td>\n",
       "      <td>2018-12-22 14:36:57.580297772+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.510151</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>2018-12-23 23:08:43.440000+00:00</td>\n",
       "      <td>-20.2855</td>\n",
       "      <td>-175.0710</td>\n",
       "      <td>113.00</td>\n",
       "      <td>6.4</td>\n",
       "      <td>mww</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.993</td>\n",
       "      <td>0.89</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>761.455537</td>\n",
       "      <td>2018-12-23 23:21:26.113940552+00:00</td>\n",
       "      <td>88.872744</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-23 23:31:24.895536552+00:00</td>\n",
       "      <td>2018-12-23 23:21:29.117955920+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.222419</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>2018-12-29 03:39:09.740000+00:00</td>\n",
       "      <td>5.8983</td>\n",
       "      <td>126.9209</td>\n",
       "      <td>60.21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>mww</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.769</td>\n",
       "      <td>1.45</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>572.353901</td>\n",
       "      <td>2018-12-29 03:48:43.312305241+00:00</td>\n",
       "      <td>56.007875</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-29 03:58:42.093901241+00:00</td>\n",
       "      <td>2018-12-29 03:48:47.688853392+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.594952</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:45:16.154043Z",
     "start_time": "2025-03-10T18:45:16.074712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "# Assuming times_df exists and contains:\n",
    "#  'expected_arrival' (datetime stored as nanoseconds),\n",
    "#  'pointed_arrival_time' (datetime stored as nanoseconds),\n",
    "#  'arrival_uncertainty' (uncertainty in nanoseconds)\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "# Define a list of file names to exclude\n",
    "exclude_files = []#['00000794.DAT','00000796.DAT']\n",
    "\n",
    "# Create a mask to keep only the rows that are NOT in the exclude list\n",
    "# mask = ~df['name'].isin(exclude_files)\n",
    "# df = df[mask]\n",
    "# print(\"DataFrame:\")\n",
    "# print(df)\n",
    "\n",
    "# Convert times to seconds (as float)\n",
    "x_abs = df['arrival_time'].values.astype(np.float64) / 1e9  # absolute expected times in seconds\n",
    "y_abs = df['observed_arrival_time'].values.astype(np.float64) / 1e9 # absolute measured times in seconds\n",
    "e_sec = df['arrival_uncertainty'].values.astype(np.float64)  # uncertainty in seconds\n",
    "\n",
    "# Use weights = 1/uncertainty for regression on absolute times\n",
    "weights = 1 / e_sec\n",
    "\n",
    "# Main weighted regression on absolute times:\n",
    "# Model: y_abs = a*x_abs + b\n",
    "(a, b), cov = np.polyfit(x_abs, y_abs, 1, w=weights, cov=True)\n",
    "var_a, var_b = np.diag(cov)\n",
    "sigma_a = np.sqrt(var_a)\n",
    "sigma_b = np.sqrt(var_b)\n",
    "\n",
    "ci_a = 1.96 * sigma_a\n",
    "ci_b = 1.96 * sigma_b\n",
    "\n",
    "drift_ppm = (a - 1) * 1e6\n",
    "ci_a_ppm = ci_a * 1e6\n",
    "\n",
    "print(\"\\nWeighted Least Squares Regression Results (with 95% CI):\")\n",
    "print(f\"Drift factor (a): {a:.12f}\")\n",
    "print(f\"Offset (b): {b:.3f} s\")\n",
    "print(f\"Drift (a - 1) in ppm: {drift_ppm:.3f} ppm (95% CI) :[ {drift_ppm - ci_a_ppm:.3f}: {drift_ppm + ci_a_ppm:.3f}] \")\n",
    "\n",
    "\n",
    "\n",
    "# --- Make a more readable scale for plotting ---\n",
    "\n",
    "# Use relative time: subtract the first expected arrival time.\n",
    "x0 = x_abs.min()  # reference time (first expected arrival)\n",
    "x_rel = x_abs - x0  # in seconds; now the x-axis starts at 0\n",
    "\n",
    "# Compute the drift (difference) in seconds and convert to microseconds for readability.\n",
    "drift_sec = y_abs - x_abs   # drift in seconds\n",
    "drift_us = drift_sec * 1e6   # convert to microseconds\n",
    "# Similarly, uncertainty in drift is the same as e_sec (if only measured arrival has uncertainty)\n",
    "e_drift_us = e_sec * 1e6     # uncertainty in microseconds\n",
    "\n",
    "# Optional: Recompute regression for the drift vs. time.\n",
    "# Note that: y_abs = a*x_abs + b  =>  drift = y_abs - x_abs = (a-1)*x_abs + b.\n",
    "# But if you shift x_abs -> x_rel = x_abs - x0, then:\n",
    "# drift = (a-1)*(x_rel+x0) + b = (a-1)*x_rel + [b + (a-1)*x0].\n",
    "drift_slope_us = (a - 1) * 1e6  # in μs per second (same as ppm, since 1 ppm = 1e-6)\n",
    "drift_intercept_us = (b + (a - 1) * x0) * 1e6\n",
    "\n",
    "# For plotting, let's convert the relative time axis to hours\n",
    "x_hours = x_rel / 3600.0  # relative time in hours\n",
    "\n",
    "# Generate fitted drift values using the regression on absolute times.\n",
    "# We'll compute drift (in μs) as: drift_fit_us = (a-1)*x_abs + b, then convert to μs.\n",
    "drift_fit_us = ((a - 1) * (x_rel + x0) + b) * 1e6\n",
    "\n",
    "# Plot the drift (in μs) versus relative time (in hours) with error bars.\n",
    "plt.figure()\n",
    "plt.errorbar(x_hours, drift_us, yerr=e_drift_us, fmt='o', capsize=5, label='Data (μs drift)')\n",
    "plt.plot(x_hours, drift_fit_us, 'r-',\n",
    "         label=f'Regression: slope = {drift_slope_us:.3f} μs/s, '\n",
    "               f'ppm (95% CI) :[{drift_ppm - ci_a_ppm:.3f}:{drift_ppm + ci_a_ppm:.3f}]')\n",
    "plt.xlabel('Time from first expected arrival (hours)')\n",
    "plt.ylabel('Drift (measured - expected) in μs')\n",
    "plt.title(\"Time Drift (Measured vs Expected) with Uncertainty\")\n",
    "# for i, name in enumerate(df['name']):\n",
    "#     name = name.split('.')[0][-4::]\n",
    "#     plt.annotate(name, (x_hours[i], drift_us[i]),\n",
    "#                  textcoords=\"offset points\", xytext=(-5,5), ha=\"right\", fontsize=8)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "141f48aa51cc3795",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weighted Least Squares Regression Results (with 95% CI):\n",
      "Drift factor (a): 1.000000140071\n",
      "Offset (b): -212.290 s\n",
      "Drift (a - 1) in ppm: 0.140 ppm (95% CI) :[ 0.074: 0.206] \n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:45:28.093839Z",
     "start_time": "2025-03-10T18:45:28.002130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = data.copy()\n",
    "import datetime as dt\n",
    "# Convert times to seconds (as float)\n",
    "x_abs = df['arrival_time'].values.astype(np.float64) / 1e9\n",
    "y_abs = df['observed_arrival_time'].values.astype(np.float64) / 1e9 # remove 10-minute addition\n",
    "e_sec = df['arrival_uncertainty'].values.astype(np.float64) # uncertainty in seconds\n",
    "\n",
    "# Compute drift (observed - expected) in seconds\n",
    "drift = y_abs - x_abs\n",
    "\n",
    "# Create a relative time axis by subtracting the minimum expected arrival time\n",
    "x0 = dt.datetime.strptime('2018-01-16 17:34:34','%Y-%m-%d %H:%M:%S')\n",
    "x0 = x0.timestamp() # reference time (first expected arrival)\n",
    "x_rel = x_abs - x0  # now x_rel starts at 0\n",
    "\n",
    "# Use weights = 1/uncertainty for regression on drift\n",
    "weights = 1 / e_sec\n",
    "\n",
    "# Perform weighted regression: drift = slope * x_rel + offset\n",
    "(slope, offset), cov = np.polyfit(x_rel, drift, 1, w=weights, cov=True)\n",
    "var_slope, var_offset = np.diag(cov)\n",
    "sigma_slope = np.sqrt(var_slope)\n",
    "sigma_offset = np.sqrt(var_offset)\n",
    "\n",
    "# For clarity, express the drift slope in parts per million (ppm) and offset in microseconds\n",
    "drift_ppm = slope * 1e6\n",
    "ci_slope_ppm = 1.96 * sigma_slope * 1e6  # 95% CI for slope in ppm\n",
    "offset_us = offset * 1e6  # offset at x_rel=0 in microseconds\n",
    "\n",
    "print(\"\\nWeighted Least Squares Regression Results (drift vs. relative time):\")\n",
    "print(f\"Drift slope: {slope:.12f} s/s, i.e. {drift_ppm:.3f} ppm (95% CI: [{drift_ppm - ci_slope_ppm:.3f}:{drift_ppm + ci_slope_ppm:.3f}])\")\n",
    "print(f\"Drift offset at reference time: {offset:.3f} s, i.e. {offset_us:.3f} μs\")\n",
    "\n",
    "# For plotting, compute the fitted drift values and convert to microseconds\n",
    "drift_fit = slope * x_rel + offset\n",
    "drift_fit_us = drift_fit * 1e6\n",
    "drift_us = drift * 1e6  # convert measured drift to microseconds\n",
    "e_drift_us = e_sec * 1e6  # uncertainty in microseconds\n",
    "\n",
    "# Convert relative time to hours for plotting\n",
    "x_hours = x_rel / 3600.0\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(x_hours, drift_us, yerr=e_drift_us, fmt='o', capsize=5, label='Data (μs drift)')\n",
    "plt.plot(x_hours, drift_fit_us, 'r-',\n",
    "         label=f'Regression: slope = {drift_ppm:.3f} ppm (95% CI: [{drift_ppm - ci_slope_ppm:.3f}:{drift_ppm + ci_slope_ppm:.3f}])')\n",
    "plt.xlabel('Time from first expected arrival (hours)')\n",
    "plt.ylabel('Drift (observed - expected) in μs')\n",
    "plt.title(\"Time Drift (Measured vs. Expected) with Uncertainty\")\n",
    "for i, name in enumerate(df['place']):\n",
    "    short_name = name.split('.')[0][-4:]  # extract a shorter name\n",
    "    plt.annotate(short_name, (x_hours[i], drift_us[i]),\n",
    "                 textcoords=\"offset points\", xytext=(-5, 5), ha=\"right\", fontsize=8)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "d77463bd307a9551",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weighted Least Squares Regression Results (drift vs. relative time):\n",
      "Drift slope: 0.000000140071 s/s, i.e. 0.140 ppm (95% CI: [0.074:0.206])\n",
      "Drift offset at reference time: 0.076 s, i.e. 76094.474 μs\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:36:47.026452Z",
     "start_time": "2025-03-10T18:36:46.820822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "def enhanced_drift_analysis(df):\n",
    "    \"\"\"\n",
    "    Perform enhanced drift analysis with weighted least squares regression\n",
    "    and comprehensive residual diagnostics.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing drift analysis data\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary with regression results and diagnostic information\n",
    "    \"\"\"\n",
    "    # Convert times to seconds (as float)\n",
    "    x_abs = df['arrival_time'].values.astype(np.float64) / 1e9\n",
    "    y_abs = df['observed_arrival_time'].values.astype(np.float64) / 1e9  # remove 10-minute addition\n",
    "    e_sec = df['arrival_uncertainty'].values.astype(np.float64)  # uncertainty in seconds\n",
    "\n",
    "    # Compute drift (observed - expected) in seconds\n",
    "    drift = y_abs - x_abs\n",
    "\n",
    "    # Create a relative time axis by subtracting the minimum expected arrival time\n",
    "    x0 = dt.datetime.strptime('2018-01-16 17:34:34','%Y-%m-%d %H:%M:%S')\n",
    "    x0 = x0.timestamp()  # reference time (first expected arrival)\n",
    "    x_rel = x_abs - x0  # now x_rel starts at 0\n",
    "\n",
    "    # Use weights = 1/uncertainty for regression on drift\n",
    "    weights = 1 / e_sec\n",
    "\n",
    "    # Perform weighted regression: drift = slope * x_rel + offset\n",
    "    (slope, offset), cov = np.polyfit(x_rel, drift, 1, w=weights, cov=True)\n",
    "    var_slope, var_offset = np.diag(cov)\n",
    "    sigma_slope = np.sqrt(var_slope)\n",
    "    sigma_offset = np.sqrt(var_offset)\n",
    "\n",
    "    # Compute drift in parts per million (ppm)\n",
    "    drift_ppm = slope * 1e6\n",
    "    ci_slope_ppm = 1.96 * sigma_slope * 1e6  # 95% CI for slope in ppm\n",
    "    offset_us = offset * 1e6  # offset at x_rel=0 in microseconds\n",
    "\n",
    "    # Compute fitted drift and residuals\n",
    "    drift_fit = slope * x_rel + offset\n",
    "    residuals = drift - drift_fit\n",
    "\n",
    "    # Residual diagnostics\n",
    "    # Compute standardized residuals\n",
    "    std_residuals = residuals / np.sqrt(e_sec**2 + (sigma_slope * x_rel)**2)\n",
    "\n",
    "    # Statistical test on residuals\n",
    "    _, shapiro_p = stats.shapiro(std_residuals)\n",
    "\n",
    "    # Plotting\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10),\n",
    "                                   gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "    # Top plot: Drift Data with Regression Line\n",
    "    x_hours = x_rel / 3600.0\n",
    "    drift_us = drift * 1e6  # convert measured drift to microseconds\n",
    "    drift_fit_us = drift_fit * 1e6\n",
    "    e_drift_us = e_sec * 1e6  # uncertainty in microseconds\n",
    "\n",
    "    ax1.errorbar(x_hours, drift_us, yerr=e_drift_us, fmt='o', capsize=5,\n",
    "                 label='Data (μs drift)')\n",
    "    ax1.plot(x_hours, drift_fit_us, 'r-',\n",
    "             label=f'Regression: slope = {drift_ppm:.3f} ppm\\n95% CI: [{drift_ppm - ci_slope_ppm:.3f}:{drift_ppm + ci_slope_ppm:.3f}]')\n",
    "\n",
    "    for i, name in enumerate(df['place']):\n",
    "        short_name = name.split('.')[0][-4:]  # extract a shorter name\n",
    "        ax1.annotate(short_name, (x_hours[i], drift_us[i]),\n",
    "                     textcoords=\"offset points\", xytext=(-5, 5),\n",
    "                     ha=\"right\", fontsize=8)\n",
    "\n",
    "    ax1.set_xlabel('Time from first expected arrival (hours)')\n",
    "    ax1.set_ylabel('Drift (observed - expected) in μs')\n",
    "    ax1.set_title(\"Time Drift (Measured vs. Expected) with Uncertainty\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Bottom plot: Residuals\n",
    "    ax2.scatter(x_hours, std_residuals, c='green', alpha=0.7)\n",
    "    ax2.axhline(y=0, color='r', linestyle='--')\n",
    "    ax2.set_xlabel('Time from first expected arrival (hours)')\n",
    "    ax2.set_ylabel('Standardized Residuals')\n",
    "    ax2.set_title('Residuals Analysis')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print detailed results\n",
    "    print(\"\\nWeighted Least Squares Regression Results:\")\n",
    "    print(f\"Drift slope: {slope:.12f} s/s, i.e. {drift_ppm:.3f} ppm\")\n",
    "    print(f\"95% Confidence Interval for slope: [{drift_ppm - ci_slope_ppm:.3f}:{drift_ppm + ci_slope_ppm:.3f}]\")\n",
    "    print(f\"Drift offset at reference time: {offset:.3f} s, i.e. {offset_us:.3f} μs\")\n",
    "\n",
    "    # Residual Diagnostics\n",
    "    print(\"\\nResidual Diagnostics:\")\n",
    "    print(f\"Shapiro-Wilk Test p-value (test for normality): {shapiro_p:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'slope': slope,\n",
    "        'drift_ppm': drift_ppm,\n",
    "        'offset': offset,\n",
    "        'ci_slope_ppm': ci_slope_ppm,\n",
    "        'shapiro_p': shapiro_p\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "results = enhanced_drift_analysis(df)"
   ],
   "id": "c428601a7f61633f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weighted Least Squares Regression Results:\n",
      "Drift slope: 0.000000064781 s/s, i.e. 0.065 ppm\n",
      "95% Confidence Interval for slope: [-0.144:0.274]\n",
      "Drift offset at reference time: 0.157 s, i.e. 157433.596 μs\n",
      "\n",
      "Residual Diagnostics:\n",
      "Shapiro-Wilk Test p-value (test for normality): 0.4592\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:35:40.106512Z",
     "start_time": "2025-03-10T18:35:40.103167Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "48e8a883a35e9618",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
