{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T07:56:54.767973Z",
     "start_time": "2025-09-19T07:56:48.835191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "ls_association_with_clock_drift.py\n",
    "Seismic event localization with clock drift estimation.\n",
    "Handles stations with unknown clock drift by initially assigning larger uncertainties\n",
    "and then estimating the drift parameters after initial localization.\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Geod\n",
    "from joblib import Parallel, delayed, Memory\n",
    "import time\n",
    "import psutil\n",
    "import pickle\n",
    "import warnings\n",
    "from utils.physics.sound_model.ellipsoidal_sound_model import GridEllipsoidalSoundModel\n",
    "# === CONFIGURATION ===\n",
    "ASSO_FILE = \"/media/rsafran/CORSAIR/Association/2018/grids/2018/s_-60-5,35-120,350,0.8,0.6.npy\"\n",
    "OUTPUT_DIR = \"/media/rsafran/CORSAIR/Association/validated\"\n",
    "OUTPUT_BASENAME = \"s_-60-5,35-120,350,0.8,0.6_with_drift\"\n",
    "CHUNK_SIZE = 25  # checkpoint every N dates\n",
    "N_JOBS = max(1, 0*os.cpu_count() - 1)  # leave one core free\n",
    "GRID_LAT_BOUNDS = [-60, 5]\n",
    "GRID_LON_BOUNDS = [35, 120]\n",
    "GRID_SIZE = 350\n",
    "ISAS_PATH = \"/media/rsafran/CORSAIR/ISAS/extracted/2018\"\n",
    "BATCH_SIZE = 5000\n",
    "#SOUND_MODEL\n",
    "arr = os.listdir(ISAS_PATH)\n",
    "file_list = [os.path.join(ISAS_PATH, fname) for fname in arr if fname.endswith('.nc')]\n",
    "SOUND_MODEL = GridEllipsoidalSoundModel(file_list)\n",
    "\n",
    "# === PERFORMANCE MONITORING ===\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "def log_progress(message):\n",
    "    elapsed = time.time() - start_time\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_usage = process.memory_info().rss / 1024 / 1024  # MB\n",
    "    print(f\"[{elapsed:.1f}s | {memory_usage:.1f}MB] {message}\")\n",
    "\n",
    "\n",
    "# === INITIALIZATION ===\n",
    "\n",
    "# Precompute grid lat/lon\n",
    "PTS_LAT = np.linspace(*GRID_LAT_BOUNDS, GRID_SIZE)\n",
    "PTS_LON = np.linspace(*GRID_LON_BOUNDS, GRID_SIZE)\n",
    "\n",
    "# Geod instance for geodesic calculations\n",
    "geod = Geod(ellps=\"WGS84\")\n",
    "\n",
    "def grid_index_to_coord(indices):\n",
    "    \"\"\"Convert grid indices to geographic coordinates\"\"\"\n",
    "    i, j = indices\n",
    "    return [PTS_LAT[i], PTS_LON[j]]\n",
    "\n",
    "def process_date(date, associations_list):\n",
    "    res = []\n",
    "    # Create simplified associations list to avoid serialization issues\n",
    "    simplified_associations = []\n",
    "    for detections, valid_points in associations_list:\n",
    "        simple_detections = []\n",
    "        for station_obj, det_time in detections:\n",
    "            # Extract only necessary data from station_obj\n",
    "            lat, lon = station_obj.get_pos()\n",
    "            drift = station_obj.get_clock_error(det_time) if \"not_ok\" in station_obj.other_kwargs.values() else 0\n",
    "            station_name = station_obj.name  # Get station name\n",
    "            simple_detections.append(((lat, lon), det_time, drift, station_name))\n",
    "        simplified_associations.append((simple_detections, valid_points))\n",
    "\n",
    "    for detections, valid_points in simplified_associations:\n",
    "        # Skip tiny clusters\n",
    "        if len(detections) < 7:\n",
    "            continue\n",
    "\n",
    "        # Build refined detections & station positions\n",
    "        station_positions = [pos for pos, _,_, _ in detections]\n",
    "        detection_times = [t for _, t,_, _ in detections]\n",
    "        drifts = [d for _,_,d, _ in detections]\n",
    "        print(np.array(valid_points))\n",
    "        c0 = np.mean(np.array(valid_points), axis=0)\n",
    "        print(c0)\n",
    "        r, _, _ = SOUND_MODEL.localize_with_uncertainties(\n",
    "            station_positions, detection_times, drift_uncertainties=drifts, initial_pos=c0\n",
    "        )\n",
    "        res.append(r)\n",
    "\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Main execution function\"\"\"\n",
    "log_progress(f\"Starting with {N_JOBS} workers\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load input\n",
    "log_progress(f\"Loading associations from {ASSO_FILE}\")\n",
    "associations = np.load(ASSO_FILE, allow_pickle=True).item()\n",
    "items = list(associations.items())\n",
    "total_items = len(items)\n",
    "log_progress(f\"Found {total_items} date entries to process\")\n",
    "\n",
    "# Process in batches with checkpoints\n",
    "validated_associations = {}\n",
    "\n",
    "for batch_start in range(0, total_items, BATCH_SIZE):\n",
    "    batch_end = min(batch_start + BATCH_SIZE, total_items)\n",
    "    batch = items[batch_start:batch_end]\n",
    "\n",
    "    log_progress(f\"Processing batch {batch_start + 1}-{batch_end} of {total_items}\")\n",
    "\n",
    "    # Process batch in parallel\n",
    "    # Note: we use a smaller chunk_size when jobs > 1 for better load balancing\n",
    "    effective_chunk = 1 if N_JOBS > 1 else CHUNK_SIZE\n",
    "\n",
    "    results = Parallel(n_jobs=1, verbose=5, batch_size=effective_chunk)(\n",
    "        delayed(process_date)(date, lst) for date, lst in batch\n",
    "    )\n",
    "\n",
    "    # Store results\n",
    "    i= 0\n",
    "    for res in results:\n",
    "        if res:  # Only store if we have validated results\n",
    "            validated_associations[i]\n",
    "            i+=1\n",
    "\n",
    "    # Checkpoint\n",
    "    chkpt_path = os.path.join(\n",
    "        OUTPUT_DIR,\n",
    "        f\"{OUTPUT_BASENAME}_partial_{batch_end}.npy\"\n",
    "    )\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        np.save(chkpt_path, validated_associations)\n",
    "\n",
    "    log_progress(f\"Checkpoint saved: {chkpt_path}\")\n",
    "\n",
    "    # Memory optimization: save and reload larger checkpoints\n",
    "    if len(validated_associations) > 5000:\n",
    "        log_progress(\"Checkpointing and refreshing memory...\")\n",
    "        pickle_path = os.path.join(OUTPUT_DIR, \"temp_checkpoint.pkl\")\n",
    "        with open(pickle_path, 'wb') as f:\n",
    "            pickle.dump(validated_associations, f)\n",
    "\n",
    "        # Clear and reload\n",
    "        validated_associations.clear()\n",
    "        with open(pickle_path, 'rb') as f:\n",
    "            validated_associations = pickle.load(f)\n",
    "\n",
    "        # Force garbage collection\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "# Final save\n",
    "log_progress(\"Saving final results\")\n",
    "final_path = os.path.join(OUTPUT_DIR, f\"{OUTPUT_BASENAME}_final.npy\")\n",
    "np.save(final_path, validated_associations)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "log_progress(f\"All done! Final results saved to {final_path}\")\n",
    "log_progress(f\"Total execution time: {elapsed:.1f} seconds ({elapsed / 60:.1f} minutes)\")\n"
   ],
   "id": "d5715403d4cebf39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0s | 191.2MB] Starting with 1 workers\n",
      "[0.0s | 191.2MB] Loading associations from /media/rsafran/CORSAIR/Association/2018/grids/2018/s_-60-5,35-120,350,0.8,0.6.npy\n",
      "[4.1s | 2949.5MB] Found 13575 date entries to process\n",
      "[4.1s | 2949.5MB] Processing batch 1-5000 of 13575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90 26]\n",
      " [90 27]\n",
      " [90 28]\n",
      " [90 29]\n",
      " [91 23]\n",
      " [91 24]\n",
      " [91 25]]\n",
      "[90.42857143 26.        ]\n",
      "initial pos  [90.42857143 26.        ]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Point [90.42857142857143, 26.0] outside grid bounds. pos : [[90.42857142857143, 26.0], (-38.5465, 52.9287)]",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 123\u001B[39m\n\u001B[32m    119\u001B[39m \u001B[38;5;66;03m# Process batch in parallel\u001B[39;00m\n\u001B[32m    120\u001B[39m \u001B[38;5;66;03m# Note: we use a smaller chunk_size when jobs > 1 for better load balancing\u001B[39;00m\n\u001B[32m    121\u001B[39m effective_chunk = \u001B[32m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m N_JOBS > \u001B[32m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m CHUNK_SIZE\n\u001B[32m--> \u001B[39m\u001B[32m123\u001B[39m results = \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43meffective_chunk\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    124\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_date\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlst\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlst\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\n\u001B[32m    125\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    127\u001B[39m \u001B[38;5;66;03m# Store results\u001B[39;00m\n\u001B[32m    128\u001B[39m i= \u001B[32m0\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/toolbox/toolbox12.venv/lib/python3.12/site-packages/joblib/parallel.py:1918\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1916\u001B[39m     output = \u001B[38;5;28mself\u001B[39m._get_sequential_output(iterable)\n\u001B[32m   1917\u001B[39m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m1918\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1920\u001B[39m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[32m   1921\u001B[39m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[32m   1922\u001B[39m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[32m   1923\u001B[39m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[32m   1924\u001B[39m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[32m   1925\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/toolbox/toolbox12.venv/lib/python3.12/site-packages/joblib/parallel.py:1847\u001B[39m, in \u001B[36mParallel._get_sequential_output\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1845\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_batches += \u001B[32m1\u001B[39m\n\u001B[32m   1846\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_tasks += \u001B[32m1\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1847\u001B[39m res = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1848\u001B[39m \u001B[38;5;28mself\u001B[39m.n_completed_tasks += \u001B[32m1\u001B[39m\n\u001B[32m   1849\u001B[39m \u001B[38;5;28mself\u001B[39m.print_progress()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 87\u001B[39m, in \u001B[36mprocess_date\u001B[39m\u001B[34m(date, associations_list)\u001B[39m\n\u001B[32m     85\u001B[39m     c0 = np.mean(np.array(valid_points), axis=\u001B[32m0\u001B[39m)\n\u001B[32m     86\u001B[39m     \u001B[38;5;28mprint\u001B[39m(c0)\n\u001B[32m---> \u001B[39m\u001B[32m87\u001B[39m     r, _, _ = \u001B[43mSOUND_MODEL\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlocalize_with_uncertainties\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     88\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstation_positions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdetection_times\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdrift_uncertainties\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdrifts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial_pos\u001B[49m\u001B[43m=\u001B[49m\u001B[43mc0\u001B[49m\n\u001B[32m     89\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     90\u001B[39m     res.append(r)\n\u001B[32m     93\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/toolbox/src/utils/physics/sound_model/ellipsoidal_sound_model.py:421\u001B[39m, in \u001B[36mGridEllipsoidalSoundModel.localize_with_uncertainties\u001B[39m\u001B[34m(self, sensors_positions, detection_times, drift_uncertainties, pick_uncertainties, velocity_uncertainties, x_min, y_min, x_max, y_max, initial_pos, velocities, max_iterations)\u001B[39m\n\u001B[32m    416\u001B[39m \u001B[38;5;66;03m# Vitesses\u001B[39;00m\n\u001B[32m    417\u001B[39m \u001B[38;5;66;03m# if velocities is None:\u001B[39;00m\n\u001B[32m    418\u001B[39m \u001B[38;5;66;03m#     velocities = [self.get_sound_speed(initial_pos, p, detection_times[min_date])\u001B[39;00m\n\u001B[32m    419\u001B[39m \u001B[38;5;66;03m#                   for p in sensors_positions]\u001B[39;00m\n\u001B[32m    420\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m velocities \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m421\u001B[39m     velocities = [\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_sound_speed_with_uncertainty\u001B[49m\u001B[43m(\u001B[49m\u001B[43minitial_pos\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdetection_times\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmin_date\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    422\u001B[39m                   \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m sensors_positions]\n\u001B[32m    423\u001B[39m     velocities, velocity_uncertainties = np.array(velocities)[:,\u001B[32m0\u001B[39m], np.array(velocities)[:,\u001B[32m1\u001B[39m]\n\u001B[32m    425\u001B[39m \u001B[38;5;66;03m# Temps relatifs\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/toolbox/src/utils/physics/sound_model/ellipsoidal_sound_model.py:207\u001B[39m, in \u001B[36mGridEllipsoidalSoundModel.get_sound_speed_with_uncertainty\u001B[39m\u001B[34m(self, source, sensor, date)\u001B[39m\n\u001B[32m    206\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_sound_speed_with_uncertainty\u001B[39m(\u001B[38;5;28mself\u001B[39m, source, sensor, date=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m--> \u001B[39m\u001B[32m207\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodels\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdate\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmonth\u001B[49m\u001B[43m \u001B[49m\u001B[43m-\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_sound_speed_with_uncertainty\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msensor\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/toolbox/src/utils/physics/sound_model/sound_velocity_grid.py:228\u001B[39m, in \u001B[36mSoundVelocityGrid.get_sound_speed_with_uncertainty\u001B[39m\u001B[34m(self, pos1, pos2, method)\u001B[39m\n\u001B[32m    225\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.sv_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    226\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.get_sound_speed(pos1, pos2, method=method), \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m228\u001B[39m velocities,actual_step, actual_step_m = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_along_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpos1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhich\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep_m\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    229\u001B[39m uncertainties = \u001B[38;5;28mself\u001B[39m.get_along_path(pos1, pos2, method=method, which=\u001B[33m\"\u001B[39m\u001B[33msv_err\u001B[39m\u001B[33m\"\u001B[39m)[\u001B[32m0\u001B[39m]\n\u001B[32m    231\u001B[39m valid_mask = ~(np.isnan(velocities) | np.isnan(uncertainties))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/toolbox/src/utils/physics/sound_model/sound_velocity_grid.py:125\u001B[39m, in \u001B[36mBidimensionalGrid.get_along_path\u001B[39m\u001B[34m(self, pos1, pos2, step, method, which, step_m)\u001B[39m\n\u001B[32m    114\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_along_path\u001B[39m(\u001B[38;5;28mself\u001B[39m, pos1, pos2, step=\u001B[38;5;28;01mNone\u001B[39;00m, method=\u001B[38;5;28;01mNone\u001B[39;00m, which=\u001B[33m\"\u001B[39m\u001B[33mdata\u001B[39m\u001B[33m\"\u001B[39m, step_m = \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m    115\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    116\u001B[39m \u001B[33;03m    Sample values along a geodesic path.\u001B[39;00m\n\u001B[32m    117\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    123\u001B[39m \u001B[33;03m    :return: (values, actual_step)\u001B[39;00m\n\u001B[32m    124\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcheck_positions\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mpos1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos2\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    126\u001B[39m     step = np.sqrt(\u001B[38;5;28mself\u001B[39m.lat_resolution ** \u001B[32m2\u001B[39m + \u001B[38;5;28mself\u001B[39m.lon_resolution ** \u001B[32m2\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m step \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m step\n\u001B[32m    127\u001B[39m     points, actual_step, actual_step_m = get_geodesic(pos1, pos2, step)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/toolbox/src/utils/physics/sound_model/sound_velocity_grid.py:102\u001B[39m, in \u001B[36mBidimensionalGrid.check_positions\u001B[39m\u001B[34m(self, pos)\u001B[39m\n\u001B[32m    100\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m pos:\n\u001B[32m    101\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m.lat[\u001B[32m0\u001B[39m] <= p[\u001B[32m0\u001B[39m] <= \u001B[38;5;28mself\u001B[39m.lat[-\u001B[32m1\u001B[39m] \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.lon[\u001B[32m0\u001B[39m] <= p[\u001B[32m1\u001B[39m] <= \u001B[38;5;28mself\u001B[39m.lon[-\u001B[32m1\u001B[39m]):\n\u001B[32m--> \u001B[39m\u001B[32m102\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mPoint \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mp\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m outside grid bounds. pos : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpos\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mValueError\u001B[39m: Point [90.42857142857143, 26.0] outside grid bounds. pos : [[90.42857142857143, 26.0], (-38.5465, 52.9287)]"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
