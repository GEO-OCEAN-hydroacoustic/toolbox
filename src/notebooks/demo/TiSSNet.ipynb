{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from utils.data_reading.sound_data.station import StationsCatalog\n",
    "\n",
    "import datetime\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms import Resize\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.detection.TiSSNet import TiSSNet  # seems useless but enables PyTorch to retrieve the model definition"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "catalog_path = \"../../../data/demo/dataset.yaml\"\n",
    "tissnet_checkpoint = \"../../../data/models/TiSSNet/torch_save\"\n",
    "\n",
    "stations = StationsCatalog(catalog_path)\n",
    "elan_raw = stations.by_dataset(\"OHASISBIO_2018_raw\")\n",
    "elan_raw = elan_raw.stations[0]\n",
    "manager = elan_raw.get_manager()\n",
    "\n",
    "date_start = manager.dataset_start + datetime.timedelta(seconds=100)\n",
    "date_end = date_start + datetime.timedelta(seconds=100)\n",
    "data = manager.get_segment(date_start, date_end)"
   ],
   "id": "dd5df7fb2321b1b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "spectrogram = 10*np.log10(signal.spectrogram(data, fs=240, nperseg=256, noverlap=128)[-1]).astype(np.float32)[::-1].copy()\n",
    "spectrogram = spectrogram[np.newaxis, :, :]  # add a dummy dimension, this stands for the channel number (here we are in grayscale, i.e. only one value for each pixel)\n",
    "model_det = torch.load(tissnet_checkpoint).cpu()\n",
    "\n",
    "# resize data\n",
    "input_data = Resize((128, spectrogram.shape[1]))(torch.from_numpy(spectrogram))\n",
    "# normalization\n",
    "input_data[input_data<-35] = -35\n",
    "input_data[input_data>140] = 140\n",
    "input_data = (input_data+35) / (35+140)\n",
    "\n",
    "with torch.no_grad():  # tells PyTorch that no gradient back propagation is needed (we do not train any network here)\n",
    "    res = model_det(input_data).numpy()\n",
    "\n",
    "f = plt.figure(1)\n",
    "plt.imshow(input_data[0], aspect=\"auto\", cmap=\"jet\", vmin=0, vmax=1)\n",
    "f.show()\n",
    "\n",
    "g = plt.figure(2)\n",
    "plt.plot(res)\n",
    "plt.xlim(0, len(res))\n",
    "plt.ylim(0, 1)\n",
    "g.show()"
   ],
   "id": "539e47a3426aaa13",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
