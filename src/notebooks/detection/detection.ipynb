{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-30T09:19:13.769291Z",
     "start_time": "2025-01-30T09:19:09.754736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import glob2\n",
    "import torch\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.transforms import Resize\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from utils.detection.TiSSNet import TiSSNet\n",
    "from utils.data_reading.sound_data.sound_file_manager import make_manager\n",
    "from utils.physics.signal.make_spectrogram import make_spectrogram"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T09:19:13.804878Z",
     "start_time": "2025-01-30T09:19:13.777625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sound_file_path = \"/media/plerolland/akoustik/GEODAMS/2024\"\n",
    "paths = glob2.glob(f\"{sound_file_path}/*\")\n",
    "tissnet_checkpoint = \"../../../data/models/TiSSNet/torch_save\"\n",
    "out_root = \"../../../data/detection\"\n",
    "\n",
    "# output files\n",
    "DELTA = datetime.timedelta(seconds=3600/0.98)  # /0.98 to get 1h segments\n",
    "TIME_RES = 0.5342  # duration of each spectrogram pixel in seconds\n",
    "FREQ_RES = 0.9375  # f of each spectrogram pixel in Hz\n",
    "REQ_HEIGHT = 128\n",
    "\n",
    "OVERLAP = 0.02  # overlap for models application (no link with STFT)\n",
    "STEP = (1 - OVERLAP) * DELTA\n",
    "\n",
    "TISSNET_PROMINENCE = 0.05\n",
    "ALLOWED_ERROR_S = 5\n",
    "MIN_HEIGHT = 0.05\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "device = \"cuda\""
   ],
   "id": "7fc99cf131527d2c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T09:19:14.366858Z",
     "start_time": "2025-01-30T09:19:13.903618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_det = TiSSNet().to(device)\n",
    "model_det.load_state_dict(torch.load(tissnet_checkpoint))\n",
    "\n",
    "def process_batch(batch):\n",
    "    try:\n",
    "        batch = np.array(batch)\n",
    "    except:\n",
    "        print(\"not rectangular array\")\n",
    "    batch = torch.from_numpy(batch).to(device)\n",
    "    with torch.no_grad():\n",
    "        res = model_det(batch).cpu().numpy()\n",
    "    del batch\n",
    "    torch.cuda.empty_cache()\n",
    "    return res"
   ],
   "id": "81c4a10aac9e4dd2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T12:02:02.273679Z",
     "start_time": "2025-01-30T09:19:14.395171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_dir = f\"{out_root}/TiSSNet/\"\n",
    "Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for path in paths:\n",
    "    manager = make_manager(path)\n",
    "    out_file = f\"{out_dir}/{manager.name}\"\n",
    "\n",
    "    print(f\"Starting detection on {manager.name}\")\n",
    "\n",
    "    start, end = manager.dataset_start, manager.dataset_end\n",
    "    steps = math.ceil((end - start)/STEP)\n",
    "    start_idx = 0\n",
    "    batch_dates, batch_process = [], []\n",
    "\n",
    "    # if some detection has already been run, we start where it was stopped\n",
    "    already_done = []\n",
    "    if Path(out_file).exists():\n",
    "        with open(out_file, \"rb\") as f:\n",
    "            while True:\n",
    "                try:\n",
    "                    already_done.append(pickle.load(f))\n",
    "                except EOFError:\n",
    "                    break\n",
    "        last_date = already_done[-1][0]\n",
    "        start_idx = math.floor((last_date - start) / STEP)\n",
    "\n",
    "\n",
    "    for i in tqdm(range(steps), smoothing=0.001):\n",
    "        if i < start_idx:\n",
    "            continue # this is just to fill tqdm progress bar in case we loaded an old detection file\n",
    "\n",
    "        # important : prefer index multiplication over incrementation to avoid rounding errors (i.e. seg_start = start + i * STEP >> seg_start = seg_start + STEP)\n",
    "        seg_start = start + i * STEP\n",
    "        seg_end = min(end, seg_start + DELTA)\n",
    "        if seg_start >= seg_end:\n",
    "            break\n",
    "\n",
    "        # add data to batch\n",
    "        data = manager.get_segment(seg_start, seg_end)\n",
    "        spectrogram = make_spectrogram(data, manager.sampling_f, t_res=TIME_RES, f_res=FREQ_RES, return_bins=False, normalize=True, vmin=-35, vmax=140).astype(np.float32)\n",
    "        spectrogram = spectrogram[np.newaxis, :, :]  # add a dummy dimension, this stands for the channel number (here we are in grayscale, i.e. only one value for each pixel)\n",
    "        input_data = Resize((REQ_HEIGHT, spectrogram.shape[-1]))(torch.from_numpy(spectrogram)) # resize data\n",
    "        batch_dates.append(seg_start)\n",
    "        batch_process.append(input_data)\n",
    "\n",
    "        # check if the batch is ready to be processed\n",
    "        if len(batch_process) == batch_size:\n",
    "            if batch_process[-1].shape != batch_process[0].shape or batch_process[-2].shape != batch_process[-1].shape:\n",
    "                # last (and probably the one before because of overlaps) batch has a last element shorter than the others, we thus make three batches\n",
    "                rlastlast = process_batch(batch_process[-2])\n",
    "                rlast = process_batch(batch_process[-1])\n",
    "                rfirst = process_batch(batch_process[:-2])\n",
    "                res = list(rfirst) + [rlastlast] + [rlast]\n",
    "                del batch_process # reclaim some RAM\n",
    "            else:\n",
    "                res = process_batch(batch_process)\n",
    "                del batch_process # reclaim some RAM\n",
    "\n",
    "            # now proceed to peak finding for each window to keep only the peaks\n",
    "            for i, (seg_start, r) in enumerate(zip(batch_dates, res)):\n",
    "                peaks = find_peaks(r, height=0, distance=ALLOWED_ERROR_S / TIME_RES, prominence=TISSNET_PROMINENCE)\n",
    "                time_s = peaks[0] * TIME_RES\n",
    "                peaks = [(seg_start + datetime.timedelta(seconds=time_s[j]), peaks[1][\"peak_heights\"][j]) for j in range(len(time_s)) if peaks[1][\"peak_heights\"][j] > MIN_HEIGHT]\n",
    "\n",
    "                with open(out_file, \"ab\") as f:\n",
    "                    for i, (d, p) in enumerate(peaks):\n",
    "                        pickle.dump([d, p.astype(np.float16)], f)  # we write detections as a list of (date, peak probability)\n",
    "\n",
    "            batch_dates, batch_process = [], []"
   ],
   "id": "9c35b52b3691a749",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting detection on HAMS-East\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/8061 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c75679df373c4e95a6cb5dda00be1935"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plerolland/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1040.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/plerolland/Bureau/toolbox/src/utils/physics/signal/make_spectrogram.py:13: RuntimeWarning: divide by zero encountered in log10\n",
      "  spectro = 10*np.log10(spectro)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting detection on HAMS-Centre\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/7963 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ba32e60157c4632857746148da81a34"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting detection on HAMS-North\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/7988 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a30bb9adb1245cb9de4b8087acac655"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting detection on HAMS-South\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/8002 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0780c647299a4b678ce7fc46135074cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T08:20:38.097252Z",
     "start_time": "2024-12-29T08:20:38.093926Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "12107c35e0e758f9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
