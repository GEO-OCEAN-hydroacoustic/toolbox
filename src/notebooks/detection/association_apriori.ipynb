{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-05T10:22:40.127941Z",
     "start_time": "2025-02-05T10:22:40.121946Z"
    }
   },
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import glob2\n",
    "import torch\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.transforms import Resize\n",
    "from scipy.signal import find_peaks\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "from utils.data_reading.sound_data.station import StationsCatalog\n",
    "from utils.physics.sound_model.spherical_sound_model import HomogeneousSphericalSoundModel as SoundModel\n",
    "from utils.physics.signal.make_spectrogram import make_spectrogram"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T12:50:15.683517Z",
     "start_time": "2025-02-05T12:50:08.456097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "det_dir = \"../../../data/detection/TiSSNet/GEODAMS_res/\"\n",
    "catalog_path = \"/home/plerolland/Bureau/dataset.yaml\"\n",
    "out_dir = \"../../../data/detection/association/GEODAMS_apriori_min0.05.csv\"\n",
    "\n",
    "stations = StationsCatalog(catalog_path)\n",
    "sound_model = SoundModel(sound_speed=1485.5)\n",
    "\n",
    "MIN_P = 0.05\n",
    "\n",
    "ALLOWED_DELTA = datetime.timedelta(seconds=5)\n",
    "SMALL_DELTA = datetime.timedelta(seconds=5)\n",
    "\n",
    "# a priori\n",
    "CENTER = (-37.1130600118062, 78.29794527139633)\n",
    "TOL = datetime.timedelta(seconds=100/1.5)\n",
    "\n",
    "dets = {}\n",
    "pos = {}\n",
    "for det_file in tqdm(glob2.glob(det_dir + \"*\")):\n",
    "    d = []\n",
    "    with open(det_file, \"rb\") as f:\n",
    "        while True:\n",
    "            try:\n",
    "                d.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                break\n",
    "    d = np.array(d)\n",
    "    d = d[d[:,1] > MIN_P]\n",
    "    d = d[np.argsort(d[:,0])]\n",
    "\n",
    "    # remove doublons and regularly spaced signals\n",
    "    new_d = [d[0]]\n",
    "    for i in range(1, len(d)):\n",
    "        if d[i,0] - d[i-1,0] > SMALL_DELTA:\n",
    "            if i < 3 or abs((d[i,0]-d[i-1,0]) - (d[i-1,0]-d[i-2,0])) > SMALL_DELTA and abs((d[i,0]-d[i-2,0]) - (d[i-1,0]-d[i-3,0])) > SMALL_DELTA:\n",
    "                new_d.append(d[i])\n",
    "    d = np.array(new_d)\n",
    "\n",
    "    s_name = det_file.split(\"/\")[-1]\n",
    "    dets[s_name] = d\n",
    "\n",
    "    station = stations.by_name(s_name).by_starting_year(np.min(d[:,0]).year)[0]\n",
    "    pos[s_name] = station.get_pos()\n",
    "\n",
    "    print(f\"Found {len(d)} detections for station {s_name}\")\n",
    "\n",
    "s_names = list(dets.keys())"
   ],
   "id": "ddd5f334363c5ecd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2f1815d9b08404ea34a9ac0752e2795"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 94335 detections for station HAMS-Centre\n",
      "Found 74768 detections for station HAMS-East\n",
      "Found 113107 detections for station HAMS-North\n",
      "Found 87942 detections for station HAMS-South\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T12:50:16.970463Z",
     "start_time": "2025-02-05T12:50:15.692399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "allowed_delta_mat = {s_name:{s_name_2:None for s_name_2 in s_names} for s_name in s_names}\n",
    "for i in s_names:\n",
    "    di = sound_model.get_sound_travel_time(CENTER, pos[i])\n",
    "    for j in s_names:\n",
    "        dj = sound_model.get_sound_travel_time(CENTER, pos[j])\n",
    "        allowed_delta_mat[i][j] = datetime.timedelta(seconds=dj - di)\n",
    "\n",
    "dets_merged = np.concatenate([[(s_name, det[0], det[1]) for det in dets[s_name]] for s_name in s_names])\n",
    "dets_merged = dets_merged[np.argsort(dets_merged[:,1])]"
   ],
   "id": "ebc57fcf2a9e8857",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T13:14:54.990935Z",
     "start_time": "2025-02-05T12:50:17.020567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "possible_associations = []\n",
    "done = set() # set of already used detection times\n",
    "\n",
    "with open(out_dir, \"w\") as f:\n",
    "    f.write(f\"lat,lon,date_human,date,p_mean,loc_cost\\n\")\n",
    "\n",
    "for s_name, det_date, det_p in tqdm(dets_merged):\n",
    "    if det_date in done:\n",
    "        continue\n",
    "\n",
    "    # get possibly matching detections for each other station (given expected sound travel time)\n",
    "    candidates = {}\n",
    "    for s_name_2 in s_names:\n",
    "        if s_name_2 != s_name:\n",
    "            candidates[s_name_2] = []\n",
    "            idx = np.searchsorted(dets[s_name_2][:,0], det_date + allowed_delta_mat[s_name][s_name_2] - TOL, side=\"left\")\n",
    "            idx = max(idx-1, 0)\n",
    "            if idx < len(dets[s_name_2]):\n",
    "                while dets[s_name_2][idx][0] < det_date + allowed_delta_mat[s_name][s_name_2] + TOL:\n",
    "                    if dets[s_name_2][idx][0] in done:\n",
    "                        idx += 1\n",
    "                        if idx >= len(dets[s_name_2]):\n",
    "                            break\n",
    "                        continue\n",
    "                    if dets[s_name_2][idx][0] > (det_date + allowed_delta_mat[s_name][s_name_2] - TOL):\n",
    "                        candidates[s_name_2].append((s_name_2, dets[s_name_2][idx][0], dets[s_name_2][idx][1]))\n",
    "                    idx += 1\n",
    "                    if idx >= len(dets[s_name_2]):\n",
    "                        break\n",
    "\n",
    "    # we have our candidates and make our associations\n",
    "    candidates_list = [dets for dets in candidates.values()]\n",
    "    associations = list(itertools.product(*candidates_list))\n",
    "\n",
    "    # check all associations are consistent (i.e. we know they are so with det_date but not if they are so together)\n",
    "    new_associations = []\n",
    "    for association in associations:\n",
    "        consistent = True\n",
    "        for i, (s_name_2, det_date_2, det_p_2) in enumerate(association):\n",
    "            for (s_name_3, det_date_3, det_p_3) in association[i+1:]:\n",
    "                if (det_date_3 - det_date_2 > allowed_delta_mat[s_name_2][s_name_3] + TOL or\n",
    "                    det_date_3 - det_date_2 < allowed_delta_mat[s_name_2][s_name_3] - TOL):\n",
    "                    consistent = False\n",
    "        if consistent:\n",
    "            new_associations.append(association)\n",
    "    associations = new_associations\n",
    "\n",
    "    if len(associations) == 0:\n",
    "        continue\n",
    "\n",
    "    best_a, best_loc = None, None\n",
    "    # at this point we know we have consistent association(s). We check if the location inversion works\n",
    "    for association in associations:\n",
    "        association = [(s_name, det_date, det_p)] + list(association)  # we add the main detection to the association\n",
    "        det_pos = [pos[s_name_2] for (s_name_2, _, _) in association]\n",
    "        det_dates = [det_date_2 for (_, det_date_2, _) in association]\n",
    "\n",
    "        try:\n",
    "            loc = sound_model.localize_common_source(det_pos, det_dates)\n",
    "        except LinAlgError:\n",
    "            continue\n",
    "        if best_loc is None or loc.cost < best_loc.cost:\n",
    "            best_a = association\n",
    "            best_loc = loc\n",
    "\n",
    "    if best_a and best_loc.cost < 1:\n",
    "        det_dates = [det_date_2 for (_, det_date_2, _) in best_a]\n",
    "        date = np.min(det_dates) + datetime.timedelta(seconds=best_loc.x[0])\n",
    "\n",
    "        for (s, d, p) in best_a:\n",
    "            done.add(d)\n",
    "\n",
    "        with open(out_dir, \"a\") as f:\n",
    "            f.write(f'{best_loc.x[1]},{best_loc.x[2]},{date.strftime(\"%Y%m%d_%H%M%S\")},{date.timestamp()},{np.mean(np.array(best_a)[:,2])},{best_loc.cost}\\n')"
   ],
   "id": "3af2349b57513f5b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/370152 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26262641a9454518bc6d02bf22f822c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4c1a795eca0aa546"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
